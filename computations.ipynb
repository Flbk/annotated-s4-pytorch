{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\RR}{\\mathbb{R}}\n",
    "\\newcommand{\\ZZ}{\\mathbb{Z}}\n",
    "\\newcommand{\\CC}{\\mathbb{C}}\n",
    "\\newcommand{\\EE}{\\mathbb{E}}\n",
    "\\newcommand{\\Zz}{\\mathcal{Z}}\n",
    "\\newcommand{\\Ww}{\\mathcal{W}}\n",
    "\\newcommand{\\Vv}{\\mathcal{V}}\n",
    "\\newcommand{\\Nn}{\\mathcal{N}}\n",
    "\\newcommand{\\NN}{\\mathcal{N}}\n",
    "\\newcommand{\\Hh}{\\mathcal{H}}\n",
    "\\newcommand{\\Bb}{\\mathcal{B}}\n",
    "\\newcommand{\\Ee}{\\mathcal{E}}\n",
    "\\newcommand{\\Cc}{\\mathcal{C}}\n",
    "\\newcommand{\\Gg}{\\mathcal{G}}\n",
    "\\newcommand{\\Ss}{\\mathcal{S}}\n",
    "\\newcommand{\\Pp}{\\mathcal{P}}\n",
    "\\newcommand{\\Ff}{\\mathcal{F}}\n",
    "\\newcommand{\\Xx}{\\mathcal{X}}\n",
    "\\newcommand{\\Mm}{\\mathcal{M}}\n",
    "\\newcommand{\\Ii}{\\mathcal{I}}\n",
    "\\newcommand{\\Dd}{\\mathcal{D}}\n",
    "\\newcommand{\\Ll}{\\mathcal{L}}\n",
    "\\newcommand{\\Tt}{\\mathcal{T}}\n",
    "\\newcommand{\\al}{\\alpha}\n",
    "\\newcommand{\\la}{\\lambda}\n",
    "\\newcommand{\\ga}{\\gamma}\n",
    "\\newcommand{\\Ga}{\\Gamma}\n",
    "\\newcommand{\\La}{\\Lambda}\n",
    "\\newcommand{\\si}{\\sigma}\n",
    "\\newcommand{\\Si}{\\Sigma}\n",
    "\\newcommand{\\be}{\\beta}\n",
    "\\newcommand{\\de}{\\delta}\n",
    "\\newcommand{\\De}{\\Delta}\n",
    "\\renewcommand{\\phi}{\\varphi}\n",
    "\\renewcommand{\\th}{\\theta}\n",
    "\\newcommand{\\om}{\\omega}\n",
    "\\newcommand{\\Om}{\\Omega}\n",
    "\\newcommand{\\eps}{\\varepsilon}\n",
    "\\newcommand{\\bo}[1]{\\boldsymbol{\\mathbf{#1}}}\n",
    "\\newcommand{\\bu}{\\bo{u}}\n",
    "\\newcommand{\\bv}{\\bo{v}}\n",
    "\\newcommand{\\bV}{\\bo{V}}\n",
    "\\newcommand{\\bC}{\\bo{C}}\n",
    "\\newcommand{\\bp}{\\bo{p}}\n",
    "\\newcommand{\\bq}{\\bo{q}}\n",
    "\\newcommand{\\bX}{\\bo{X}}\n",
    "\\newcommand{\\bc}{\\bo{c}}\n",
    "\\newcommand{\\bb}{\\bo{b}}\n",
    "\\newcommand{\\bh}{\\bo{h}}\n",
    "\\newcommand{\\by}{\\bo{y}}\n",
    "\\newcommand{\\lc}{\\bo{L}(\\bC)}\n",
    "\\newcommand{\\lcb}[1]{\\bo{L}(\\bo{#1})}\n",
    "\\newcommand{\\ba}{\\bo{a}}\n",
    "\\newcommand{\\bbv}{\\bo{b}}\n",
    "\\newcommand{\\tD}{\\bo{\\widetilde{D}}}\n",
    "\\newcommand{\\tLa}{\\bo{\\widetilde{\\La}}}\n",
    "\\newcommand{\\tCbe}{\\bo{\\widetilde{C}^{\\be}}}\n",
    "\\newcommand{\\bbe}{\\bo{\\beta}}\n",
    "\\newcommand{\\Cbe}{\\bC^{\\bbe}}\n",
    "\\newcommand{\\bhat}{\\bo{\\hat{\\be}}}\n",
    "\\newcommand{\\pibe}{\\bpi^{\\bbe}}\n",
    "\\newcommand{\\bD}{\\bo{D}}\n",
    "\\newcommand{\\bZ}{\\bo{Z}}\n",
    "\\newcommand{\\bF}{\\bo{F}}\n",
    "\\newcommand{\\bA}{\\bo{A}}\n",
    "\\newcommand{\\bB}{\\bo{B}}\n",
    "\\newcommand{\\bK}{\\bo{K}}\n",
    "\\newcommand{\\bI}{\\bo{I}}\n",
    "\\newcommand{\\bS}{\\bo{S}}\n",
    "\\newcommand{\\bLa}{\\bo{\\La}}\n",
    "\\newcommand{\\ctilde}{\\bo{\\tilde{c}}}\n",
    "\\newcommand{\\ptilde}{\\bo{\\tilde{p}}}\n",
    "\\newcommand{\\bhatK}{\\bo{\\hat{K}}}\n",
    "\\newcommand{\\bR}{\\bo{R}}\n",
    "\\newcommand{\\bAb}{\\bo{\\bar{A}}}\n",
    "\\newcommand{\\bbb}{\\bo{\\bar{b}}}\n",
    "\\newcommand{\\ut}{u_{<t}}\n",
    "\\newcommand{\\norm}[1]{\\|#1\\|}\n",
    "\\newcommand{\\clint}[1]{\\left[ #1 \\right]}\n",
    "\\newcommand{\\diff}{\\mathop{}\\!\\mathrm{d}}\n",
    "\\newcommand{\\dotp}[1]{\\left\\langle #1 \\right\\rangle}\n",
    "\\newcommand{\\bx}{\\bo{x}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S4 in Pytorch.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook aims at explaining the S4 layer described in [S4](https://arxiv.org/abs/2111.00396), with more details on practical use cases, as well as a simple Pytorch implementation.\n",
    "Some parts of this code are directly coming from the excellent guide [Annotated S4](https://srush.github.io/annotated-s4/).\n",
    "\n",
    "The goal of the notebook is to be as concise as possible while providing enough details for a full comprehension of a practical implementation of S4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelisation\n",
    "\n",
    "### Classical approaches\n",
    "\n",
    "Deep NLP has made huge progress since the arrival of the sequence-to-sequence models. A sequence-to-sequence model is a model that maps a sequence $u_0, \\dots, u_{L-1}$ to another sequence $y_0, \\dots, y_{L-1}$.\n",
    "\n",
    "The main approaches in NLP were first RNN, that mimics Hidden Markov Process. In simple terms, a RNN models a situation recursively:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\begin{cases}\n",
    "        h_{k+1} &=& g(u_{k+1}, h_k),\\\\\n",
    "        y_{k+1} &=& f(h_{k+1}).\n",
    "    \\end{cases}\n",
    "\\end{equation}\n",
    "where $h_k$ represents a hidden state. Here each output $y_k$ is built recursively on the precedent value $h_{k-1}$. The main drawbacks of such models is that it is extremely difficult control how the information of previous steps flows up to the current step. It has even been derived that statistically such networks doesn't have long-memory (i.e the output at step $k$ is unlikely to have retained information of $u_{k-l}$if $l$ is large enough).\n",
    "\n",
    "The other and currently SOTA architecture is the transformer.\n",
    "\n",
    "Transformers are extremelly powerful because the output sequence depends directly on *all* the previous steps:\n",
    "\n",
    "\\begin{equation}\n",
    "    y_{k+1} = \\sum_{i=0}^{k} f(u_i, u_{k+1}).\n",
    "\\end{equation}\n",
    "\n",
    "Therefore they do have long-memory. But here the problem comes form the memory consumption of such operation. To process a full sequence the memory complexity is $\\mathcal{O}(L^2)$.\n",
    "\n",
    "### State-space approach\n",
    "\n",
    "To overcome these problems, S4 introduces the formalism of state-space models. Here $u_k \\in \\RR$ is a scalar input.\n",
    "\n",
    "\\begin{equation}\\label{eq:state-space}\n",
    "    \\begin{cases}\n",
    "        x_{k+1} = \\bA x_k + \\bb u_k,\\\\\n",
    "        y_{k+1} = \\bc^T x_{k+1}.\n",
    "    \\end{cases}\n",
    "\\end{equation}\n",
    "where $x_k \\in \\RR^N$ is a vector and obviously $\\bc \\in \\RR^N$. For multidimensionnal inputs, we simply apply these steps (with the same parameters) independently to all coordinates.\n",
    "\n",
    "Let's write a first implementation of such a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseSSM:\n",
    "    def __init__(self, A, b, c):\n",
    "        self.A = A\n",
    "        self.b = b\n",
    "        self.c = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSSM(BaseSSM):\n",
    "    def __call__(self, u, L):\n",
    "\n",
    "        y = torch.zeros(L)\n",
    "        x_k = 0\n",
    "        for i in range(L):\n",
    "            x_k += b * u[i]\n",
    "            y_k = self.c.T @ x_k\n",
    "            y[i] = y_k\n",
    "            x_k = self.A @ x_k\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "L = 5\n",
    "\n",
    "A = torch.randn(N, N)\n",
    "b = torch.rand(N, 1)\n",
    "c = torch.rand(N, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_ssm = SimpleSSM(A, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5249b802b0>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_interval = torch.arange(L)\n",
    "u = torch.sin(2 * torch.pi * torch.arange(L) / L)\n",
    "plt.plot(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5247a0da90>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAlkElEQVR4nO3deXiU5bk/8O9Dksm+kj0Bwg7ZA4EqVgUURUBAtuBpT489bW1PbcWVum+11rWItv1ZT+upPe2RJGwiIm6guJsJWUjY98lC9n2bJPP8/pgBI07IBOZdZub7ua5cWWaY984L8+Wd+33ee4SUEkREpF8jtC6AiIgujEFNRKRzDGoiIp1jUBMR6RyDmohI57yVeNDIyEiZlJSkxEMTEbmlwsLCeilllL3bFAnqpKQkGI1GJR6aiMgtCSFODXYbWx9ERDrHoCYi0jkGNRGRzjGoiYh0jkFNRKRzDGoiIp1jUBMR6RyDmojICXYfrMVrn56Auc/i9MdmUBMROcErHx/DP744CR8v4fTHdjiohRBeQogiIcR2p1dBROTCTtZ34KsTjViZPQpCaBjUANYAOOD0CoiIXFx+oQkjBLB8WqIij+9QUAshEgEsBPBXRaogInJR/RaJjYUVmD05GrGhfopsw9Ej6hcBrAUwaJdcCHGrEMIohDDW1dU5ozYiIt3bc7gONa09WJWtzNE04EBQCyEWAaiVUhZe6H5SylellNlSyuyoKLuT+oiI3E6e0YSRgQbMnRKj2DYcOaK+AsBiIcRJABsAzBVC/FOxioiIXERDew8+OFCDm7ISYPBWbhHdkI8spbxfSpkopUwCsBrALinlDxWriIjIRWwpqkRvv8SqGaMU3Q7XURMRXQQpJfKMJmSOCsOkmGBFtzWsoJZSfiSlXKRUMURErqLY1IzDNe3IUfhoGuARNRHRRckzVsDfxwuL0uMU3xaDmohomDrNfXirpAoL0uIQ7Oej+PYY1EREw/TOvjNo7+lTdO30QAxqIqJhyjWaMDYyEDPHRqiyPQY1EdEwnKjvwNcnGrEyO1GRAUz2MKiJiIYh36jsACZ7GNRERA7q67dg094KzJkcjZgQZQYw2cOgJiJy0J4j1gFMK7OVXzs9EIOaiMhBeQUViAwy4Jqp0apul0FNROSA+gEDmHy81I1OBjURkQO2FlWizyKxSuW2B8CgJiIakpQSuQUmZI0Ow0SFBzDZw6AmIhpCkakZR2rbkaPB0TTAoCYiGlK+0QR/Hy8sVGEAkz0MaiKiC7AOYKrGwnR1BjDZw6AmIrqAHecGMGnT9gAY1EREF5RXYMK4yEDMSArXrAYGNRHRII7XtePrk41YmT1KtQFM9jCoiYgGkV9YAa8RAsunJWhaB4OaiMiOvn4LNhVWYM7kKESrOIDJHgY1EZEdHx+uQ22b+gOY7GFQExHZkWc0ITLIgLlT1B3AZA+DmojoPHVtPfjwQC2WTUtUfQCTPdpXQESkM1uKKmwDmNR7F5cLYVATEQ0gpUSesQLTRodhQrT6A5jsYVATEQ2w93Qzjta2I2eG9icRz2JQExENkG80IcDghYXp8VqXcg6DmojIpqOnD2+VVGFhWhyCfL21LuccBjURkc2OfdXoMPfrqu0BMKiJiM7JM5owLioQ08doN4DJHgY1ERGsA5gKTjZhlcYDmOxhUBMRAcgzWgcwLdN4AJM9DGoi8nh9/RZs2luBOZOjER2s7QAmexjUROTxPjpUh7q2Ht1ciXg+BjUReTzrACZfzNHBACZ7GNRE5NHq2nqw62Atlk9L0MUAJnv0WRURkUo277UOYNLD3OnBMKiJyGNZBzCZMH1MOCZEB2ldzqAY1ETksfaebsKxug7k6PhoGnAgqIUQfkKIr4UQJUKIciHE42oURkSktLyCCgQYvLAgPU7rUi7IkakjPQDmSinbhRA+AD4VQrwjpfxS4dqIiBTT0dOH7aVVWJSurwFM9gxZnZRSAmi3fetj+5BKFkVEpLS3dTqAyR6HetRCCC8hRDGAWgDvSym/snOfW4UQRiGEsa6uzsllEhE5V16BdQDTtNH6GsBkj0NBLaXsl1JmAkgEMFMIkWrnPq9KKbOllNlRUVFOLpOIyHmO1bXDeKoJOTocwGTPsFZ9SCmbAewGMF+RaoiIVJBnNMFrhMBNOhzAZI8jqz6ihBBhtq/9AcwDcFDhuoiIFNHbb8GmwkrMnaLPAUz2OHKqMw7A60IIL1iDPU9KuV3ZsoiIlPHRoTrUt/dglc7XTg/kyKqPUgBZKtRCRKS43AITooJ9MWey65xL45WJROQxatu6sftQLZZNS4C3Tgcw2eM6lRIRXaLNeyvRb5Eu1fYAGNRE5CHODmDKHhOO8VH6HcBkD4OaiDxC4akmHK/rwCoXuBLxfAxqIvIIeUYTAg1eWJim7wFM9jCoicjttff0YXtpNRalxyNQ5wOY7GFQE5Hb21FajU5zv0u2PQAGNRF5gFyjCeOjAjFtdJjWpVwUBjURubWjte0oPNWEnBmuMYDJHgY1Ebm1fKMJ3iMEbspK1LqUi8agJiK31dtvwaa91gFMUcG+Wpdz0RjUROS2dh+sdbkBTPYwqInIbeUZrQOYZrvQACZ7GNRE5JZqW7ux+1Adlk9LdKkBTPa4dvVERIPYdG4Ak+ueRDyLQU1EbkdKiXyjCTOSwjHOxQYw2cOgJiK3YzzVhOP1HS5/EvEsBjURuZ28AtsApnTXG8BkD4OaiNxKe08f3t5XjRsz4hFgcL0BTPYwqInIrbxdWuXSA5jsYVATkVvJLTBhQnQQskaFaV2K0zCoichtHK1tw97TzcjJdt0BTPYwqInIbeQZK6wDmKYlaF2KUzGoicgt9PZbsHlvBa6ZGo3IINcdwGQPg5qI3MKug7Wobze7zdrpgdxj7QqRjZQSHeZ+NLab0dhpRmNHDxo7es99nj05CpeNG6l1maSAvAITooN9cfUk1x7AZA+DmnStr9+Cps5eNHWa0dButn7uMKOpw4zGAR/nftZphrnPMujjvf75Sbx7x1UYPTJAxd+ClFbT2o3dh2rx86vHu/wAJnsY1KQaKSU6zf3fCthzH53mAUfB1tBt6DCjpat30McL9vNGRKABEYEGJIT5ITU+BBFBBkQEGM79fOBHW3cfrl+3B/duLMEbP7sMI0a4z6oAT7dpbwUsEm7Z9gAY1HQJ+i0STZ3fhOp3Pnd+N5B7Bjna9R4hvhWqU+NDMDLQgPAAA0YG2T4HGhAeaP0cFmCAwXt4R07Bfj54eFEy1m4qxT++OIlbrhjrjN1AGrMOYKrAzKQIjI0M1LocRTCo6ZxOc5/9o11b6A5sPTTajnaltP9Ywb7eCLeFbkyIH6bGhXwTxLYj3rOhGxFkQLCvtyrrXldmJ2JHWTWe2XkIc6ZEY8xI93xie5KCk004Ud+B2+ZM0LoUxTCo3VS/RaKlq/dbJ9MGPeq1tRy6e+0f7XqNEAOOaH0wNTYE4YE+iAj0/dZR7tmj37AAH/h6e6n8GztGCIGnl6Vj3rqPce/GUmxgC8Tl5RlNCPL1xoK0WK1LUQyD2oV9drQenx+rPxfETR29aOjoOXfybbCj3UCDl7WXG+iLqCBfTI4JQYQteL/zOcCAEH91jnbVEhvqh0cWJePejaV4/YuT+DFbIC6rrbsXb5dWY2mW+wxgssd9fzM3V3S6CT967WsAQHiAj7WVEGDA5Njgb/Vzzz+hFh5ggJ+PPo921bRieiLeKTuDZ3YexOzJ0W7b23R3b5dWo6u3321PIp7FoHZBbd29WLOhGLEhftix5kqE+vtoXZLLEULgqZvScN26j7F2Ywlyb72cLRAXlGs0YWJ0EDLdaACTPe634NADPLqtHBVNnVi/OpMhfQliQ/3w6I0pKDjZhP/5/KTW5dAwHalpQ9HpZuTMcK8BTPYwqF3Mm8WV2Ly3Er+eOxHZSRFal+Pylk1LwDVTovHszoM4XteudTk0DHlGE7xHCCzNcq8BTPYwqF2IqbETD20pw/Qx4fj1XPddiqQmIQSeWpYGPx8v3LuxFP2WQc7Akq6Y+yzYvLcS106NcbsBTPYwqF1EX78FazYUAQBezMl0y8tktRIT4ofHFiej8FQT/uezE1qXQw7YdbAWDR1mrJqRqHUpquCz3UW8vOso9p5uxu+WpWFUBOdUONvSzARcOzUGz717CMfYAtG9PKMJMSG+uGqi+w1gsmfIoBZCjBJC7BZC7BdClAsh1qhRGH2j4GQjXt51BMumJWBxRrzW5bgl6yqQVGsLJL+ELRAdq2ntxkeHarF8WqLHvLJ05LfsA3C3lDIZwGUAbhNCJCtbFp3V0tWLOzYUIzE8AE8sSdW6HLcWHeKHJ5akYO/pZvzt0+Nal0OD2Fjo3gOY7BkyqKWU1VLKvbav2wAcAOD+p1l1QEqJB7fsQ01rN166OQtBvlz2rrTFGfG4LjkGz793GEdr2QLRG+sAJhNmjo1AkgddpDSs1w1CiCQAWQC+snPbrUIIoxDCWFdX56TyPNumvZXYXlqNO+dNcvsF/XohhMCTN6UiwOCFe9gC0Z2vTzTiZEMncjzoaBoYRlALIYIAbAJwh5Sy9fzbpZSvSimzpZTZUVGe0eBX0sn6DjzyZhm+NzYCv7h6vNbleJToYD88vjgFxaZm/PcnbIHoSZ6xwjaAKU7rUlTlUFALIXxgDel/SSk3K1sSmfssuH1DEXy8RmBdTia8eGmz6hZnxGN+Siz+8P5hHK1t07ocgnV0wo591bgxIx7+Bs+aV+PIqg8B4G8ADkgp/6B8SbTug8MorWjB08vSEB/mr3U5HkkIgd8uTUWgwQt355eir3/wt/cidWy3DWDKmeFZbQ/AsSPqKwD8O4C5Qohi28cChevyWJ8fq8crHx/DzTNH4QYPe3mnN1HBvnhiSSpKTM14lS0QzeUWmDApJggZiaFal6K6IZcRSCk/BcDX3ipo6jDjrtwSjI0MxMOLuAJSDxalx+Gdsmq8+P4RXDs1BpNigrUuySMdrmlDsakZDy2c6vYDmOzxjNXiLkBKifs2l6Khowcvrc5y6yHorkQIgSeWpCLIzxv35JewBaKRvAITfLwEbvKAAUz2MKh14o2vTXi3vAZrr5+C1ATPe2mnZ5FBvvjtklSUVrTgL3vYAlGbuc+CzUXWAUwjPWAAkz0Mah04WtuOJ7aX48qJkfjJ9/m2UHq0MD0OC9Pi8OIHh3HoDFeBqGnXwRo0dpg96krE8zGoNdbT14/b3yhCgMEbL6zM4LuM6NgTS1IQ4ueDe/JL0MsWiGpyC0yIDfHDVZM89/oMBrXGntt5CPurW/Hs8nREh/hpXQ5dwMggXzy5NBX7Klvwl4+PaV2ORzjT0o2PD9dh+fQEj76egEGtoT2H6/DXT0/gR5ePwbXJMVqXQw64IS0Oi9LjsP7DIzhQ/Z0LdMnJNu31vAFM9jCoNVLf3oO78kowKSYIDyyYqnU5NAxPLElFqD9bIEqTUiLPaMJl4yIwZqTnDGCyh0GtASkl1m4sRWt3L166OQt+Pp51Oayriwg04MmlaSivasX/+4gtEKV8daIRpxo6Pf5oGmBQa+IfX5zCroO1eOCGKZgSG6J1OXQR5qfGYnFGPF7edQT7q9gCUUKe0YRgX2/ckMordBnUKjt4phW/23EAcyZH4T9mJWldDl2CxxenINTfwBaIAlrPDmDK9LwBTPYwqFXU3duPNW8UI8TPB8+tzPDIS2HdSXigAU/dlIr91a340+6jWpfjVraXVKO71+Jxc6cHw6BW0e93HMChmja8sCrDI97i3hNclxKLpZnx+OOuoyivatG6HLeRazRhckww0j1wAJM9DGqVfHigBq9/cQo/+f5YXO3BC/fd0WOLUxAeaMDdeSUw97EFcqkOnWlDiakZq2aM4qtOGwa1Cmpbu3HvxlJMjQvB2vmTtS6HnCwswICnbkrDwTNt+CNbIJcsz+jZA5jsYVArzGKRuDu/BJ3mPrx8cyZ8vXlixB3NS47BsqwE/Hn3UZRVsgVyscx9FmwpqsS85BhEBBq0Lkc3GNQKe+2zE/jkSD0eXpSMCdGcZezOHr0xBRGB1lUgbIFcnA8PWAcwreRJxG9hUCuorLIFz+w8iOuSY/BvM0drXQ4pLDTAB79fZm2BvLzriNbluKRco20A00SexxmIQa2QTnMfbt9QhIhAA55Zns6TIh7imqkxWDYtAX/+6Bj2VbAFMhzVLV3Yc7gOK6YnevQAJnsY1Ar57fb9OFHfgXWrMhHOXptHeXRRCiKDrC2Qnr5+rctxGZsKOYBpMAxqBewsq8YbX5vw86vGY9aESK3LIZWFBvjg6WXpOFTThpc+ZAvEERaLRJ6xApePG4nRIwO0Lkd3GNROVt3Shd9s2of0xFDcNW+S1uWQRuZMicaK6Yl45ePjKK1o1roc3fvqRCNON3Zi1YxErUvRJQa1E/VbJO7MLUZvvwXrV2fB4M3d68keXpSMqCBftkAckG80IdiPA5gGwyRxolc+PoYvjzfi8cUpGBvp2fNzCQj198Hvl6fhcE071n/AFshgWrt7saOsGosz4jnydxAMaicpNjVj3fuHsTA9Dium8+UbWc2ZHI1V2Yl45eNjKDY1a12OLm0rrrIOYJrBk4iDYVA7QXtPH9ZsKEJMiB+eWprGpXj0LQ8tSkZMiB/uyS9Bdy9bIOfLN5owJTYYaQkcwDQYBrUTPPpmOUyNnViXk4nQAB+tyyGdCfHzwdPL03G0th0vsgXyLQfPtKKkogWrsjmA6UIY1JdoW0kVNu2twK/mTsTMsRFal0M6dfWkKKyeMQqv7jmGvaebtC5HN/IKKuDjJbCUA5guiEF9CUyNnXhwyz5MGx2G2+dO0Loc0rkHF05FbIgf7mULBADQ09ePLUUVuC45lgOYhsCgvkh9/RbcmVsMSGD96ix4e3FX0oUF21ogx+o6sO79w1qXo7kPD9SiqbMXK7N58n0oTJeL9MfdR2E81YQnb0rFqAheSUWOuWpSFG6eORr//clxFJ7y7BZIboEJ8aF+uJIDmIbEoL4IxpONeOnDI1iWlYAlmeyt0fA8sGAK4kL9PboFUtXchT1HOIDJUQzqYWrt7sWaDcVIDA/A40tStC6HXFCwnw+eWZ6O4/UdeOG9Q1qXo4lNhRWQElgxnWunHcGgHgYpJR7cUoYzrd1YvzoTwX5cikcX5/sTI/GD743GXz89gcJTjVqXoyqLRSK/sAKzxnMAk6MY1MOweW8l3iqpwp3XTkTW6HCtyyEXd/+CqYgP9cc9+aXoMntOC+TLEw3WAUwcZ+owBrWDTtZ34JE3yzBzbAT+azaX4tGlC/L1xnMr0nGivgPPe1ALJN9YgWA/b8xPjdW6FJfBoHZAb78Fa3KL4TVC4MWcTJ78IKeZNSESP7xsNF777AQKTrp/C6Slqxc79lVjSSYHMA0Hg9oBL35wGCWmZjy9PB3xYf5al0Nu5v4bpiIhzLoKxN1bINtKqtDTZ0FONt9DdDgY1EP44lgD/vzRMeRkj8KCNM7KJecL9PXGcysycLKhE8++e1DrchR1dgBTakKI1qW4FAb1BTR3mnFnbjHGjgzEIzcma10OubHLx4/Ejy4fg79/fhJfn3DPFsiB6laUVrQgZwYHMA3XkEEthHhNCFErhChToyC9kFLivk370NDRg/WrsxDo6611SeTmfjN/ChLD/XHvxhJ0mvu0Lsfp8owmGLxGYCkvEhs2R46o/w5gvsJ16E5ugQk7y8/gnusmIy2Rc3JJeWdbIKcaOvHsTvdaBWIdwFSJeSkxCOcApmEbMqillHsAuOdrsUEcrW3H42/txxUTRuJnV47TuhzyIJeNG4lbZiXh75+fxJfHG7Qux2k+2F+L5s5erp2+SE7rUQshbhVCGIUQxrq6Omc9rOp6+vqxZkMR/HxG4A+rMjGCS/FIZWvnT8aYkQFYu7HUbVoguUbrAKbvT4jUuhSX5LSgllK+KqXMllJmR0W57jSsF947jPKqVjy7IgMxIX5al0MeKMBgbYGYmjrxzDuuvwqkqrkLnxypw4rsUbwG4SJx1ccAnxypw6t7juOHl43GvOQYrcshDzZzbARumZWE1784hc+P1WtdziXZaBvAtJJv+nzRGNQ2De09uCuvBBOjg/DgAi7FI+2tvX4KkmwtkI4e12yBWAcwmXDFhJGc234JHFme9waALwBMFkJUCCF+onxZ6pJSYu3GUrR09eKlm7Pgb+ClraQ9f4MXnluZgcrmLjztoi2QL483wNTYxZOIl2jIxcFSypvVKERL//vlKXx4sBaP3piMqXG8Yor0Y0ZSBP7zirH426cncENqLGa52Mm4PKMJIX7euD6FA5guhce3Pg6dacPv3j6A2ZOjcMusJK3LIfqOe66bjLGRgbh3YynaXagF0tLVi3fKzmBJZgIHMF0ijw7q7t5+3P5GEYL9rGfZeVkr6ZG/wQvPrUhHVUsXfr/jgNblOGxbcaV1ANMMtj0ulUcH9dPvHMShmjY8vzIDUcG+WpdDNKjspAj85Iqx+NdXp/HpEddYBZJnrMDUuBCkxLOdeKk8Nqh3HazB3z8/if+8YixmT47WuhyiId1z/WSMiwzEbzaVoq27V+tyLmh/VSv2VbYgJzuRr1SdwCODuratG/fml2JKbDDWzp+sdTlEDvHzsa4CqW7pwlM79L0K5OwApiUcwOQUHhfUFovE3XklaO/pw8s3Z/EkB7mU6WPC8dMrx+GNr0/jkyP6HNXQ09ePrcWVuI4DmJzG44L6tc9O4JMj9Xh4UTImxgRrXQ7RsN01bxLGRwXiNxv12QJ5f38NBzA5mUcFdXlVC57deQjzkmPwg+/xrYDINfn5eOH5lRk409qN372tv1UguQUmJIT5cwCTE3lMUHeZrUvxwgJ88MzydJ7gIJeWNTocP7tqHDYUmPDxYf20QCqbu/Dp0XqsmJ7IyZNO5DFB/du39+N4fQfW5WQign0zcgN3XjsJE6KDcN+mUrTqpAWy0VgBAFjBAUxO5RFBvbPsDP7vq9O49apxuIIvx8hNnG2B1LR248nt+7Uu55sBTOMjOYDJydw+qM+0dOO+zaVISwjF3fO4FI/cS+aoMPz86vHIM1Zg96FaTWv54ngDKpq6sDKbR9PO5tZB3W+RuDO3GD29FqxfnQmDt1v/uuSh7rh2IiZGB+H+TfvQ0qVdCyS3gAOYlOLWyfXqnuP44ngDHl+cgnFRQVqXQ6QIX29rC6SuvUezFkhLZy92lp/B0iwOYFKC2wZ1iakZL7x3CAvT4vhSjNxexqgw/OLqccgvrMCugzWqb//NkkqY+yxcO60Qtwzqjp4+rNlQhOhgXzx1UxqX4pFHuP2aiZgcE4z7N+9DS6e6LZA8ownJcSFITQhVdbuewi2D+rFt5Tjd2Il1OZkIDfDRuhwiVZxtgdS3m/GEii2Q8qoWlFW2cpypgtwuqN8qqUJ+YQVumzMB3xs3UutyiFSVlhiKX84ej017K/DBfnVaIPnGChi8R2BJZrwq2/NEbhXUFU2deGDLPmSNDsPt10zUuhwiTfx67kRMiQ3GA1uUb4F09/ZjS1Elrk+JRVgALyRTitsEdV+/BXfmFkNKYH1OFny83OZXIxoWg/cIPL8yAw0dZjz+Vrmi23p/fw1aunqRw5OIinKbNPvzR8dQcLIJv12agtEjeVUUebbUhFDcNns8NhdV4n0FWyB5RusAplnj2WZUklsEdeGpRqz/8AiWZsbjpiwuxSMCgF8NaIE0d5qd/vgVTZ349Gg9VmZzAJPSXD6oW7t7sWZDMeLD/PDE0lStyyHSDYP3CLywKgNNHWY8ts35LZCNhRzApBaXD+qHt5ahuqUbL+ZkIcSPS/GIBkqJD8VtcyZga3EV3i0/47THtVgk8o0V+P6ESCSGs9WoNJcO6i1FFXizuAprrpmI6WPCtS6HSJdumzMBU+NC8OCWMjR1OKcF8vmxBlQ2d2ElTyKqwmWD+lRDBx7eWo6ZSRG4bc4Ercsh0i2D9wi8sDIDzZ1mPOqkFkiu0YRQfx9clxzjlMejC3PJoO7tt2DNhmIIAaxbnQkvnsgguqDk+BD8eu5EbCupws6yS2uBNHea8W75GSzNjOcAJpW4ZFCv/+AIik3N+P2yNCSE+WtdDpFL+OWc8UiJD8FDW/eh8RJaIG8WV1kHMPGScdW4XFB/ebwBf/roKFZOT8SidF6ySuQoHy/rhTAtXb145M2yi36cPKMJKfEhSInnACa1uFRQt3T24s7cYiSNDMRji1O0LofI5UyNC8Htcydie2k13tlXPew/X1bZgvIqDmBSm8sEtZQS928pRV1bD9avzkSgr7fWJRG5pF/MHo/UhBA8tLUMDe09w/qz+UaTdQBTRoJC1ZE9LhPUeUYTduw7g3uun4z0xDCtyyFyWWdbIK3dvXjkTcdXgXT39mNrcRXmp8RyfLDKXCKoj9W147Ft+zFr/EjceuU4rcshcnlTYkNwx7WT8Pa+arxd6lgL5L2zA5jY9lCd7oPa3GfBmg1F8PUZgT+syuRMASIn+flV45CeGIqH3yxDvQMtkLwCExLD/XE557yrTvdB/cJ7h1BW2YpnlqcjNtRP63KI3Ia3rQXS3t2Hh7eWQUo56H1NjZ347Fg9Vk4fxYMlDeg6qD89Uo+/7DmOH3xvNN+CnkgBk2KCsebaiXin7Ay2X6AFcm4AE98oWhO6DerGDjPuyivGhOggPLQwWetyiNzWz68ah4zEUDzyZhnq2r7bAum3SGwstA5g4gVm2tBlUEspsXZjKZo7e/HS6iz4G3iZKpFSzrZAOnr68dDWfd9pgXx+rB6VzV1YxQFMmtFlUP/zq9P44EANfnPDFCTHh2hdDpHbmxgTjDvnTcK75TXYVlL1rdtyC0wIC/DBdSkcwKQVh4JaCDFfCHFICHFUCHGfkgUdrmnDk9v34+pJUfjxrCQlN0VEA/zsyrHIHBWGR7eVo7atG4B1ANN75TVYmpkAX2++stXKkEEthPAC8CcANwBIBnCzEEKRpnF3bz9uf6MIwX7eeH5lBs8uE6nobAuk09yPh7ZYV4FsLaqEud/CtofGHDmingngqJTyuJTSDGADgCVKFPPMzoM4eKYNz63IQFSwrxKbIKILmBAdhLvnTcJ7+60tkDxjBVITQtiC1JgjQZ0AwDTg+wrbz75FCHGrEMIohDDW1dUNu5DmTjPeKqnCLbOSMGdK9LD/PBE5x0+vHIes0WG4b9M+7K9uRQ6PpjXntJOJUspXpZTZUsrsqKioYf/5sAADdqy5EvfdMMVZJRHRRfAaIfD8ygxYpITBewQWcwCT5hwZQVcJYOB/qYm2nzlddDCvPCTSg/FRQViXk4mWrl4OYNIBR4K6AMBEIcRYWAN6NYB/U7QqItLcgrQ4rUsgmyGDWkrZJ4T4FYB3AXgBeE1K6Zx3yCQioiE5NH1fSrkDwA6FayEiIjt0eWUiERF9g0FNRKRzDGoiIp1jUBMR6RyDmohI5xjUREQ6Jy70PmkX/aBC1AE4dZF/PBJAvRPLcRbWNTysa3hY1/C4Y11jpJR2528oEtSXQghhlFJma13H+VjX8LCu4WFdw+NpdbH1QUSkcwxqIiKd02NQv6p1AYNgXcPDuoaHdQ2PR9Wlux41ERF9mx6PqImIaAAGNRGRzmkW1EKI+UKIQ0KIo0KI++zc7iuEyLXd/pUQIkkndd0ihKgTQhTbPn6qQk2vCSFqhRBlg9wuhBAv2WouFUJMU7omB+uaLYRoGbCvHlGprlFCiN1CiP1CiHIhxBo791F9nzlYl+r7TAjhJ4T4WghRYqvrcTv3Uf356GBdqj8fB2zbSwhRJITYbuc25+4vKaXqH7C+AcExAOMAGACUAEg+7z6/BPCK7evVAHJ1UtctAP6o8v66CsA0AGWD3L4AwDsABIDLAHylk7pmA9iuwb+vOADTbF8HAzhs5+9R9X3mYF2q7zPbPgiyfe0D4CsAl513Hy2ej47UpfrzccC27wLwf/b+vpy9v7Q6op4J4KiU8riU0gxgA4Al591nCYDXbV9vBHCNEELooC7VSSn3AGi8wF2WAPiHtPoSQJgQQvH3UXKgLk1IKaullHttX7cBOADg/HdoVX2fOViX6mz7oN32rY/t4/xVBqo/Hx2sSxNCiEQACwH8dZC7OHV/aRXUCQBMA76vwHf/wZ67j5SyD0ALgJE6qAsAltteLm8UQoyyc7vaHK1bC5fbXrq+I4RIUXvjtpecWbAejQ2k6T67QF2ABvvM9jK+GEAtgPellIPuLxWfj47UBWjzfHwRwFoAlkFud+r+4snE4XsLQJKUMh3A+/jmf036rr2wzi/IAPAygK1qblwIEQRgE4A7pJStam77QoaoS5N9JqXsl1JmAkgEMFMIkarGdofiQF2qPx+FEIsA1EopC5Xe1llaBXUlgIH/8yXafmb3PkIIbwChABq0rktK2SCl7LF9+1cA0xWuyRGO7E/VSSlbz750ldb33fQRQkSqsW0hhA+sYfgvKeVmO3fRZJ8NVZeW+8y2zWYAuwHMP+8mLZ6PQ9al0fPxCgCLhRAnYW2PzhVC/PO8+zh1f2kV1AUAJgohxgohDLA227edd59tAP7D9vUKALukrTOvZV3n9TEXw9pn1No2AD+yrWS4DECLlLJa66KEELFn+3JCiJmw/ntT/Mlt2+bfAByQUv5hkLupvs8cqUuLfSaEiBJChNm+9gcwD8DB8+6m+vPRkbq0eD5KKe+XUiZKKZNgzYhdUsofnnc3p+4vh96F3NmklH1CiF8BeBfWlRavSSnLhRBPADBKKbfB+g/6f4UQR2E9YbVaJ3XdLoRYDKDPVtctStclhHgD1tUAkUKICgCPwnpiBVLKV2B9h/gFAI4C6ATwY6VrcrCuFQD+SwjRB6ALwGoV/rMFrEc8/w5gn62/CQAPABg9oDYt9pkjdWmxz+IAvC6E8IL1P4Y8KeV2rZ+PDtal+vNxMEruL15CTkSkczyZSESkcwxqIiKdY1ATEekcg5qISOcY1EREOsegJiLSOQY1EZHO/X/LJQ/egD2uywAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = simple_ssm(u, L)\n",
    "plt.plot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State-space computations\n",
    "\n",
    "Now let's take a step back and remember that our goal is to train a model, whose parameters will include $\\bA, \\bb, \\bc$.\n",
    "\n",
    "However if the formulation of \\eqref{eq:state-space} seems simple, it is in fact quite complicated for training, due do its recursive definition (same problems faced during training of RNN actually).\n",
    "\n",
    "A big advantage of transformers is the possibility to process in parallel the whole sequence, that greatly improves the training speed and the backpropagation of the gradient is more easy than with recursive architectures.\n",
    "\n",
    "Hence a legitimate question is: do we have the same property with S4? And the answer is yes!\n",
    "\n",
    "To explain it, we are now going to focus exclusively on training, i.e when the full input and output are already available. Later, we will explain how we can generate outputs in an autoregressive manner.\n",
    "\n",
    "## Training - Convolution view\n",
    "\n",
    "One can notice that if we unrol \\eqref{eq:state-space}, $y \\in \\RR^L$ can be directly expressed as a convolution between the input $u \\in \\RR^L$ and a filter $\\bK \\in \\RR^L$:\n",
    "\n",
    "\\begin{align}\n",
    "    y_0 &= \\bc^T\\bb u_0,\\\\\n",
    "    y_1 &= \\bc^T\\bA\\bb u_0 + \\bc^T\\bb u_1,\\\\\n",
    "    y_2 &= \\bc^T \\bA^2 \\bb u_0 + \\bc^T\\bA\\bb u_1 + \\bc^T\\bb u_2,\\\\\n",
    "    \\vdots\\\\\n",
    "    y_k &= \\sum_{i=0}^k \\bc^T\\bA^i\\bb u_{k - i}.\n",
    "\\end{align}\n",
    "\n",
    "We have therefore: $y = \\bK * u$, with $\\bK = \\left(\\bc^T \\bb, \\bc^T\\bA\\bb, \\dots, \\bc^T\\bA^{L-1}\\bb\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good news: a convolution can be computed in $\\mathcal{O}(L \\log L)$ once the filter $\\bK$ is known, using Discrete Fourier Transform (with padding to avoid circular convolution).\n",
    "\n",
    "Compared to the quadratic complexity of transformers, we have a huge gain in term of memory usage.\n",
    "\n",
    "Let's write a first function to see what it gives.\n",
    "\n",
    "*Remark:* In the following code you will see some functions characteristic of hermitian product in a complex vector space. This is because later we will work in $\\CC^N$ instead of $\\RR^N$. For now you can ignore it and just think of `c.H` as `c.T` for the adjoint operator and ignore `c.conj()` (that we use sometimes to compute the adjoint operator indirectly).\n",
    "\n",
    "But sometimes some operations are also needed because of floating points error (like taking the real part after inverse Fourier Transform). When there is ambiguity we will write some comments in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_simple(A, b, c, L):\n",
    "    K = [(c.H @ A.matrix_power(l) @ b).item() for l in range(L)]\n",
    "    return torch.tensor(K)\n",
    "\n",
    "def causal_convolution(u, K):\n",
    "    convolution_shape = u.shape[0] + K.shape[0]\n",
    "    \n",
    "    # Specifying the paramter 'n' will automatically pad our vectors to the right dimension.\n",
    "    u_fft = torch.fft.fft(u, n=convolution_shape)\n",
    "    K_fft = torch.fft.fft(K, n=convolution_shape)\n",
    "    out = u_fft * K_fft\n",
    "\n",
    "    # This will give complex outputs.\n",
    "    return torch.fft.ifft(out)[: u.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConvSSM(BaseSSM):\n",
    "    \n",
    "    def __call__(self, u, L):\n",
    "    \n",
    "        K = kernel_simple(self.A, self.b, self.c, L)\n",
    "        y = causal_convolution(u, K)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_conv_ssm = SimpleConvSSM(A, b, c)\n",
    "y_conv = simple_conv_ssm(u, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(y.type(torch.complex64), y_conv, atol=1e-3) # we need to cast y to complex type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the main bottleneck of this computation is how we obtain the convolution kernel. We exponentiate a matrix $L$ times, compute a lot of matrix products etc, which is highly non efficient and non stable from a numerical point of view.\n",
    "\n",
    "To make this more efficient, we can find more sophisticated algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Namely, instead of computing directly $\\bK$, we are going to compute its DFT, $\\bhatK$ and then simply apply a inverse Fourier Transform (IDFT). Let $\\om_k = \\exp\\left(-{\\dfrac{2i \\pi k}{N}}\\right)$.\n",
    "\n",
    "\\begin{align}\\label{eq:K-spectrum}\n",
    "    \\bhatK_k &= \\sum_{i=0}^{L-1} \\bK_i \\omega_k^i,\\\\\n",
    "    &= \\sum \\bc^T A^i b \\omega_k^i,\\\\\n",
    "    &= \\bc^T \\left(\\sum \\bA^i \\omega_k^i \\right) \\bb,\\\\\n",
    "    &= \\bc^T (\\bI - \\bA^L)(\\bI - \\bA\\omega_k)^{-1} \\bb.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this does not really reduce the complexity, because now we have to compute an inverse $L$ times (for each $\\om_k$), giving a complexity of $\\mathcal{O}(LN^3)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretization and special decomposition\n",
    "\n",
    "TLDR: Instead of directly dealing with the matrices $\\bA$ and $\\bb$ we are going to use slightly modified versions $\\bAb, \\bbb$. This is because of a discretization process.\n",
    "\n",
    "\\begin{equation}\n",
    "    \\begin{cases}\n",
    "        \\bAb &= \\left(\\bI - \\dfrac{1}{2}\\bA \\right)^{-1}\\left(\\bI + \\dfrac{1}{2}\\bA\\right),\\\\\n",
    "        \\bbb &= \\left(\\bI - \\dfrac{1}{2}\\bA \\right)^{-1}\\bb.\n",
    "    \\end{cases}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize(A, b, step=1):\n",
    "    I = torch.eye(A.shape[0])\n",
    "    left_term = torch.linalg.inv(I - (step / 2.0) * A)\n",
    "    A_bar = left_term @ (I + (step / 2.0) * A)\n",
    "    b_bar = (left_term * step) @ b\n",
    "    return A_bar, b_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also assume that $\\bA$ is similar to a matrix of the form $\\bLa - \\bp^* \\bp$, where we now considerate matrix and vectors with coefficients in $\\CC$.\n",
    "Where $\\bLa \\in \\CC^{N \\times N}$ is diagonal and $\\bp \\in \\CC^{N \\times 1}$.\n",
    "$.^*$ designated the hermitian adjoint (= transpose + conjugate) of a matrix (a vector is viewed as a matrix of $\\CC^{N \\times 1}$).\n",
    "This decomposition is called Diagonal Plus Low Rank (DPLR).\n",
    "\n",
    "*Remark:* In the original article the derivations are made with $\\bA \\sim \\bLa + \\bq^* \\bp$. But in practice in S4 we use $-\\bp = \\bq$ which is valid and works better for numerical reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, the matrix $A$ we are using can be decomposed in the following form:\n",
    "\\begin{equation}\n",
    "    \\bA = - \\dfrac{1}{2}\\bI - \\bS - \\bp^*\\bp,\n",
    "\\end{equation}\n",
    "where $\\bS$ is a skew-hermitian matrix ($\\bS = - \\bS^*$), and $\\bp \\in \\RR^{N}$ is a vector of dimension 1.\n",
    "\n",
    "And in the adapted basis, the inverse of a DLPR matrix is much more easy to compute, thanks to the Woodburry inversion formula:\n",
    "\n",
    "\\begin{equation}\n",
    "    (\\bLa - \\bp^* \\bq)^{-1} = \\bLa^{-1} + \\bLa^{-1}\\bp \\left(1 - \\bq^*\\bLa^{-1} \\bp\\right)^{-1}\\bq^* \\bLa^{-1}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we apply this result to the expression of $\\bhatK$ \\eqref{eq:K-spectrum} using $\\bAb$ and $\\bbb$, with some more algebraic operations, we obtain a quite simple formula for its expression:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\bhatK_k = \\dfrac{2}{1 + \\om_k}\\left[\\ctilde^* \\bR_k \\bb - \\ctilde^* \\bR_k \\bp (1 + \\bp^*\\bR_k \\bp)^{-1}\\bp^*\\bR_k \\bb\\right].\n",
    "\\end{equation}\n",
    "\n",
    "with $\\bR_k = \\left(2\\dfrac{1 - \\om_k}{1 + \\om_k} - \\bLa \\right)^{-1}$ and $\\ctilde^* = \\bc^* (\\bI - \\bAb^L)$.\n",
    "\n",
    "And here, in fact all the matrix multiplications can be evaluated very efficiently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\\label{eq:cauchy-K}\n",
    "   \\ctilde^T \\bR_k \\bb &= \\sum_{i=1}^{N} \\dfrac{\\ctilde_i \\bb_i}{\\om_k - \\bLa_i},\n",
    "\\end{align}\n",
    "\n",
    "and because we want to compute it for all $\\om_k$, the complexity reduces to $\\mathcal{O}(NL)$.\n",
    "In fact, we can be even more efficient, but we need to rely on algorithms that are not yet implemented on Pytorch.\n",
    "But notice that this complexity is not a bottleneck when the biggest memory cost comes from the size of the sequence.\n",
    "\n",
    "Computing operation \\eqref{eq:cauchy-K} for all $k$ is actually a Cauchy product, a well studied problem in the litterature. We are going to implement it in a naive way, but again it won't be the main bottleneck of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_c_tilde(A, c, L):\n",
    "    I = torch.eye(A.shape[0])\n",
    "    \n",
    "    # .H returns the adjoint operator (equivalent to transpose with real inputs).\n",
    "    return (I - A.matrix_power(L)).H @ c\n",
    "\n",
    "def cauchy(p, q, Lambd, omega_L):\n",
    "    omega_L = 2. * ((1. - omega_L) / (1 + omega_L))\n",
    "    \n",
    "    dot_product = p.conj() * q\n",
    "\n",
    "    Lambd = Lambd[:, None]\n",
    "    omega_L = omega_L[None, :]\n",
    "    cauchy_product = dot_product / (omega_L - Lambd)\n",
    "    return cauchy_product.sum(axis=-2)\n",
    "\n",
    "def kernel_dplr(Lambd, p, b, c_tilde, L):\n",
    "    omega_L = torch.exp((-2j * torch.pi) * torch.arange(L) / L)\n",
    "    term_1 = cauchy(c_tilde, b, Lambd, omega_L)\n",
    "    term_2 = cauchy(c_tilde, p, Lambd, omega_L)\n",
    "    term_3 = 1. / (1. + cauchy(p, p, Lambd, omega_L))\n",
    "    term_4 = cauchy(p, b, Lambd, omega_L)\n",
    "    \n",
    "    K_fft = (2. / (1. + omega_L)) * (term_1 - term_2 * term_3 * term_4) \n",
    "    return torch.fft.ifft(K_fft, L)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random DPLR decomposition.\n",
    "Lambd = -torch.rand(N, dtype=torch.complex64) # use negative real parts to get more stability\n",
    "p = torch.randn(N, 1, dtype=torch.complex64)\n",
    "b = torch.randn(N, 1, dtype=torch.complex64)\n",
    "c = torch.randn(N, 1, dtype=torch.complex64)\n",
    "\n",
    "A = torch.diag(Lambd) - p @ p.H\n",
    "A_bar, b_bar = discretize(A, b)\n",
    "c_tilde = compute_c_tilde(A_bar, c, L)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the computations of the kernel yields the same result than with a naive approach.\n",
    "K_dplr = kernel_dplr(Lambd, p, b, c_tilde, L)\n",
    "K_simple = kernel_simple(A_bar, b_bar, c, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(K_simple, K_dplr, atol=1e-4, rtol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientConvSSM(BaseSSM):\n",
    "    def __init__(self, Lambd, p, b, c):\n",
    "        self.Lambd = Lambd\n",
    "        self.p = p\n",
    "        self.b = b\n",
    "        self.c = c\n",
    "        \n",
    "    def __call__(self, u, L):\n",
    "        A = torch.diag(self.Lambd) - p @ p.H\n",
    "        A_bar, _ = discretize(A, self.b)\n",
    "        c_tilde = compute_c_tilde(A_bar, c, L)\n",
    "        K = kernel_dplr(self.Lambd, p, b, c_tilde, L)\n",
    "        y = causal_convolution(u, K)\n",
    "        return y\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compares efficient implentation with the naive one.\n",
    "efficient_conv_ssm = EfficientConvSSM(Lambd, p, b, c)\n",
    "y_efficient_conv = efficient_conv_ssm(u, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_conv_ssm = SimpleConvSSM(A_bar, b_bar, c)\n",
    "y_simple_conv = simple_conv_ssm(u, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(y_efficient_conv, y_simple_conv, atol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multidimensionnal data\n",
    "\n",
    "Until now we have supposed that our sequence $\\bu$ is 1D. As said earlier, a direct way to generalize everything is to apply all this processing to all dimensions independently.\n",
    "\n",
    "And in addition we are also going to consider a batch dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseMultiSSM:\n",
    "    def __init__(self, A, b, c):\n",
    "        self.A = A # (H, N, N)\n",
    "        self.b = b # (H, N, 1)\n",
    "        self.c = c # (H, N, 1)\n",
    "        \n",
    "class SimpleMultiConvSSM(BaseMultiSSM):\n",
    "    def __call__(self, u, L):\n",
    "        y = torch.zeros_like(u)\n",
    "        for batch_dim in range(u.shape[0]):\n",
    "            for hidden_dim in range(u.shape[2]):\n",
    "                A_hidden = self.A[hidden_dim]\n",
    "                b_hidden = self.b[hidden_dim]\n",
    "                c_hidden = self.c[hidden_dim]\n",
    "                K = kernel_simple(A, b, c, L)\n",
    "                y[batch_dim, :, hidden_dim] = causal_convolution(u[batch_dim, :, hidden_dim], K)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first vectorize the discretization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_multi(A, b, step=1):\n",
    "    I = torch.eye(A.shape[1])\n",
    "    left_term = torch.linalg.inv(I[None, :, :] - (step / 2.0) * A)\n",
    "    A_bar = left_term @ (I + (step / 2.0) * A)\n",
    "    b_bar = (left_term * step) @ b[:, :, None]\n",
    "    return A_bar, b_bar.reshape(b.shape[0], -1)\n",
    "\n",
    "def discretize_multi_simple(A, b, step=1):\n",
    "    A_bar = torch.zeros_like(A)\n",
    "    b_bar = torch.zeros_like(b)\n",
    "    for h in range(A.shape[0]):\n",
    "        A_bar[h], b_bar[h] = discretize(A[h], b[h], step=step)\n",
    "    return A_bar, b_bar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 3\n",
    "A = torch.randn(H, N, N)\n",
    "b = torch.randn(H, N)\n",
    "c = torch.randn(H, N)\n",
    "A_bar, b_bar = discretize_multi(A, b)\n",
    "A_bar_simple, b_bar_simple = discretize_multi_simple(A, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_bar, b_bar = discretize_multi(A, b)\n",
    "A_bar_simple, b_bar_simple = discretize_multi_simple(A, b)\n",
    "\n",
    "assert torch.allclose(A_bar_simple, A_bar)\n",
    "assert torch.allclose(b_bar, b_bar_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a utility function to help us \"vectorize\" our unidimensionnal functions for testing (it just does a for loop but it will help us avoid repeating code).\n",
    "\n",
    "This roughly does the same than the manual implementation of `discretize_multi_simple`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_multi(func):\n",
    "    \"\"\"Makes a function handle multi dimensionnal inputs.\n",
    "    This is not optimized and should only be used for testing purposes.\"\"\"\n",
    "    def multi_inputs(*args):\n",
    "        out = []\n",
    "        hidden_dim = args[0].shape[0]\n",
    "\n",
    "        args = list(args)\n",
    "        for i in range(len(args)):\n",
    "            if (not isinstance(args[i], torch.Tensor)):\n",
    "\n",
    "                args[i] = [args[i] for _ in range(hidden_dim)]\n",
    "\n",
    "        for h in range(hidden_dim):\n",
    "            out.append(func(*[input_tensor[h] for input_tensor in args]).tolist())\n",
    "        return torch.tensor(out)\n",
    "    return multi_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the kernel generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_c_tilde_multi(A, c, L):\n",
    "    # A (H, N, N)\n",
    "    # c (H, N)\n",
    "    c_tilde = (torch.eye(A.shape[1])[None, :, :] - A.matrix_power(L)).mH @ c[:, :, None]\n",
    "    return c_tilde.view(c_tilde.shape[0], -1)\n",
    "\n",
    "def cauchy_multi(p, q, Lambd, omega_L):\n",
    "    \"\"\"Multidimensionnal Cauchy product. Basically we are just using broadcasting to generalize above function.\"\"\"\n",
    "    # p, q, Lambd (H, N)\n",
    "    # omega_L (L,)\n",
    "    omega_L = 2. * ((1. - omega_L) / (1 + omega_L))\n",
    "    dot_product = p.conj() * q\n",
    "\n",
    "    Lambd = Lambd[:, :, None]\n",
    "    omega_L = omega_L[None, None, :]\n",
    "    cauchy_product = dot_product[:, :, None] / (omega_L - Lambd)\n",
    "    return cauchy_product.sum(axis=-2)\n",
    "\n",
    "def kernel_dplr_multi(Lambd, p, b, c_tilde, L):\n",
    "    omega_L = torch.exp((-2j * torch.pi) * torch.arange(L) / L)\n",
    "    term_1 = cauchy_multi(c_tilde, b, Lambd, omega_L)\n",
    "    term_2 = cauchy_multi(c_tilde, p, Lambd, omega_L)\n",
    "    term_3 = 1. / (1. + cauchy_multi(p, p, Lambd, omega_L))\n",
    "    term_4 = cauchy_multi(p, b, Lambd, omega_L)\n",
    "    \n",
    "    K_fft = (2. / (1. + omega_L[None, :])) * (term_1 - term_2 * term_3 * term_4) \n",
    "    return torch.fft.ifft(K_fft, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_tilde = compute_c_tilde_multi(A, c, L)\n",
    "\n",
    "compute_c_tilde_multi_simple = make_multi(compute_c_tilde)\n",
    "c_tilde_simple = compute_c_tilde_multi_simple(A, c, L)\n",
    "\n",
    "# Check if our vectorized function gives the same result than the a naive one.\n",
    "assert torch.allclose(c_tilde, c_tilde_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with complex inputs, just to make sure we will be able to generalize with these kind of inputs.\n",
    "p = torch.randn(H, N, dtype=torch.complex64)\n",
    "p = torch.randn(H, N, dtype=torch.complex64)\n",
    "q = torch.randn(H, N, dtype=torch.complex64)\n",
    "Lambd = torch.randn(H, N, dtype=torch.complex64)\n",
    "omega_L = torch.exp((-2j * torch.pi) * torch.arange(L) / L)\n",
    "\n",
    "prod = cauchy_multi(p, q, Lambd, omega_L)\n",
    "\n",
    "cauchy_multi_simple = make_multi(cauchy)\n",
    "prod_simple = cauchy_multi_simple(p[:, :, None], q[:, :, None], Lambd, omega_L.expand(H, L))\n",
    "\n",
    "assert torch.allclose(prod_simple, prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.randn(H, N, dtype=torch.complex64)\n",
    "b = torch.randn(H, N, dtype=torch.complex64)\n",
    "c = torch.randn(H, N, dtype=torch.complex64)\n",
    "Lambd = torch.randn(H, N, dtype=torch.complex64)\n",
    "\n",
    "K = kernel_dplr_multi(Lambd, p, b, c, L)\n",
    "\n",
    "kernel_dplr_multi_simple = make_multi(kernel_dplr)\n",
    "\n",
    "K_simple = kernel_dplr_multi_simple(Lambd, p[:, :, None], b[:, :, None], c[:, :, None], L)\n",
    "\n",
    "# Compare the kernels with our vectorized and naive approaches.\n",
    "assert torch.allclose(K, K_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def causal_convolution_multi(u, K):\n",
    "    fft_shape = u.shape[2] + K.shape[1]\n",
    "    u_fft = torch.fft.fft(u, n=fft_shape, axis=-1)\n",
    "    K_fft = torch.fft.fft(K, n=fft_shape, axis=-1)\n",
    "    out = u_fft * K_fft\n",
    "    return torch.fft.ifft(out, axis=-1)[:, :, :u.shape[2]]\n",
    "\n",
    "\n",
    "def causal_convolution_multi_simple(u, K):\n",
    "    out = torch.zeros_like(u)\n",
    "    for i in range(u.shape[0]):\n",
    "        for j in range(u.shape[1]):\n",
    "            out[i, j, :] = causal_convolution(u[i, j, :], K[j])\n",
    "    return out\n",
    "\n",
    "\n",
    "def test_convolution_multi(batch_size=8, seq_length=10, hidden_size=5):\n",
    "    \"\"\"Function to test if the multidimensionnal convolution works.\"\"\"\n",
    "    u = torch.randn(batch_size, hidden_size, seq_length)\n",
    "    K = torch.randn(hidden_size, seq_length)    \n",
    "    \n",
    "    y_simple = causal_convolution_multi_simple(u, K)\n",
    "    y = causal_convolution_multi(u, K)\n",
    "    assert torch.allclose(y.real, y_simple, atol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15105/3641897104.py:13: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  ../aten/src/ATen/native/Copy.cpp:239.)\n",
      "  out[i, j, :] = causal_convolution(u[i, j, :], K[j])\n"
     ]
    }
   ],
   "source": [
    "test_convolution_multi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to implement everything in a `nn.Module` class.\n",
    "We have indeed a desribed a valid model whose parameters are $\\bLa, \\bb, \\bp, \\bc$.\n",
    "\n",
    "There is however a last detail on which we should spend some time. Indeed, we are going to initialize $\\bLa, \\bb, \\bp$ with very special values. This is also this initializatin which is going to explain why this S4 model works so well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HiPPO matrix\n",
    "\n",
    "First a bit of context. In the previous section we have introduced a discretized version as well as DPLR decomposition for $\\bA$. But the main contribution of the article is to provide a value of $\\bA$ that will efficiently keep in memory the information on the whole sequence.\n",
    "\n",
    "To do that, let's go back in the continuous domain and consider $u(t)$, $u \\colon \\RR^+ \\to \\RR$ a scalar continuous function. Because we are in the end interesting in autoregressive generation, let's introduce $\\ut = u \\mathbf{1}_{\\clint{0, t}}$. And what the authors propose is to approximate this function on a polynomial basis.\n",
    "\n",
    "For time $t$ we choose an orthogonal polynomial basis $(P_n^t)_{0\\leq n \\leq N-1}\\in \\RR_N[X]$ for the scalar product $\\dotp{u, v} = \\displaystyle\\int_0^t u v \\diff \\lambda$ (typically we orthogonalize the canonical basis).\n",
    "\n",
    "$\\forall n \\in [0..N-1]$ the coefficients $x_n(t)$ of the projection are simply given by:\n",
    "\n",
    "\\begin{equation}\\label{eq:coefs}\n",
    "    x_n(t) = \\displaystyle\\int_0^t u(s) P^t_n(s) \\diff s.\n",
    "\\end{equation}\n",
    "\n",
    "When we differentiate \\eqref{eq:coefs} (see the original paper for the details), we find something that again depends on the $x_1, \\dots, x_N$ and $\\ut$, hence we have an ODE of the form:\n",
    "\n",
    "\\begin{equation}\\label{eq:ode}\n",
    "    \\dfrac{d \\bx}{dt}(t) = \\bA \\bx(s) + u(s)\\bb(s),\n",
    "\\end{equation}\n",
    "with \\textbf{tractable} $\\bA \\in \\RR^{N \\times N}$ and $\\bb \\in \\RR^N$.\n",
    "\n",
    "At each time $t$, $\\bx(t) \\in \\RR^N$ represents the whole function $\\ut$. Hence, the memory property.\n",
    "\n",
    "And it happens that for the Legend polynomial basis, the matrices $\\bA$ and $\\bb$ have a closed form expression:\n",
    "\n",
    "\\begin{array}{rrrl}\n",
    "    \\forall i, j \\in [0..N-1], & \\, \\bA_{ij} & = & -\n",
    "    \\begin{cases}\n",
    "        (2i + 1)^{1/2}(2j + 1)^{1/2} &\\quad \\text{if} \\, i > j,\\\\\n",
    "        i + 1 &\\quad \\text{if} \\, i = j,\\\\\n",
    "        0 &\\quad \\text{if} \\, i < j,\n",
    "    \\end{cases}\\\\\n",
    "    \\forall i \\in [0..N-1], & \\, \\bb_i & = & (2i + 1)^{1/2}.\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hippo_matrices(N):\n",
    "    u = torch.arange(N)\n",
    "    b = torch.sqrt(2 * u[:, None] + 1)\n",
    "    A = b @ b.T\n",
    "    A = torch.tril(A, 0)\n",
    "    A = - (A - torch.diag(u))\n",
    "\n",
    "    return A, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000, -0.0000, -0.0000, -0.0000],\n",
       "        [-1.7321, -2.0000, -0.0000, -0.0000],\n",
       "        [-2.2361, -3.8730, -3.0000, -0.0000],\n",
       "        [-2.6458, -4.5826, -5.9161, -4.0000]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, b = hippo_matrices(4)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we notice immediately that if $\\ptilde = \\dfrac{1}{\\sqrt{2}}\\bb$, then:\n",
    "\n",
    "\\begin{align}\n",
    "    \\bA + \\ptilde \\ptilde^t &= -\\begin{cases}\n",
    "        \\dfrac{1}{2}(2i + 1)^{1/2}(2j + 1)^{1/2} &\\quad \\text{if} \\, i > j,\\\\\n",
    "        \\dfrac{1}{2} &\\quad \\text{if} \\, i = j,\\\\\n",
    "        -\\dfrac{1}{2}(2i + 1)^{1/2}(2j + 1)^{1/2} &\\quad \\text{if} \\, i < j,\n",
    "    \\end{cases}\\\\\n",
    "    &= -\\dfrac{1}{2}\\bI - \\bS\n",
    "\\end{align}\n",
    "where $\\bS$ is a skew-symmetric matrix:\n",
    "\n",
    "\\begin{equation}\n",
    "\\bS =\n",
    "\\begin{cases}\n",
    "        \\dfrac{1}{2}(2i + 1)^{1/2}(2j + 1)^{1/2} &\\quad \\text{if} \\, i > j,\\\\\n",
    "        0 &\\quad \\text{if} \\, i = j,\\\\\n",
    "        -\\dfrac{1}{2}(2i + 1)^{1/2}(2j + 1)^{1/2} &\\quad \\text{if} \\, i < j,\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "And a skew-symmetric matrix can be diagonalized (in $\\CC$), hence it means that $\\bA$ is similar to a DPLR matrix!\n",
    "\n",
    "\\begin{equation}\n",
    "\\exists \\bV \\in \\mathcal{O}_N(\\CC),\\, \\bA = \\bV \\left( \\bLa - \\bp \\bp^* \\right) \\bV^*,\n",
    "\\end{equation}\n",
    "\n",
    "with $\\bV$ the matrix representing the (complex) eigenvectors of $\\bS$, $\\mathcal{O}_N(\\CC)$ the set of orthogonal matrices of size $N$ in $\\CC$, and $\\bp = \\bV^* \\ptilde$.\n",
    "Note that we should not forget to also change the basis of $\\bb$ when we want to use the special form $\\bA = \\bLa - \\bp \\bp^*$.\n",
    "\n",
    "We now have everything to initialize our parameters:\n",
    "\n",
    "- Create $\\bA, \\bp$ and $\\bb$ with their closed form expressions.\n",
    "- Instead of optimizing $\\bc$ we are going to optimize $\\ctilde$ which is in fact the only part where $\\bc$ is used. It will help reducing the number of operations and especially avoid exponentiating $\\bA$ (this is however a bit incorrect because we are losing the property that the output is real, but we can hope the neural network will learn a 'good' $\\ctilde$ which in the end has this property).\n",
    "- Initialize $\\ctilde$ at random.\n",
    "- Extract $\\bS$ from $\\bA$ and compute its eigenbasis.\n",
    "- Change the basis of $\\bp, \\bb$.\n",
    "- Initialize $\\bD$ at random that we are going to use as a \"skip connection\".\n",
    "\n",
    "From now all our vectors are going to be complex.\n",
    "\n",
    "Let's write that in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hippo_matrices_dplr(N):\n",
    "    u = torch.arange(N)[:, None]\n",
    "    \n",
    "    p_tilde = torch.sqrt(u + 0.5)\n",
    "\n",
    "    # Construct S\n",
    "    S = torch.tril(p_tilde @ p_tilde.T)\n",
    "    S = - S + S.T\n",
    "\n",
    "    # A small trick to make a skew-hermitian matrix a hermitian one.\n",
    "    hermitian_S = S * -1j\n",
    "    \n",
    "    # Diagonalize S and extract V.\n",
    "    Lambda, V = torch.linalg.eigh(hermitian_S)\n",
    "\n",
    "\n",
    "    # Mutliplies back the eigenvalues by (1j)^-1 to retrieve the original eigenvalues of the skew-hermitian matrix.\n",
    "    # We have to add the real parts of the eigenvalues, coming for the 1/2*Id part of the decomposition. \n",
    "    Lambda = Lambda * 1j - 0.5\n",
    "    \n",
    "    b = torch.sqrt(2 * u + 1)\n",
    "    \n",
    "    # Change of basis for b and p.\n",
    "    b = V.H @ b.type(torch.complex64)\n",
    "    p = V.H @ p_tilde.type(torch.complex64)\n",
    "    \n",
    "    return V, Lambda, p, b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "V, Lambda, p, b = hippo_matrices_dplr(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if we did not make any mistakes in our change of basis by comparing $\\bA$ obtained from the direct formula and the one obtained through diagonalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, b = hippo_matrices(N)\n",
    "\n",
    "assert torch.allclose(V @ (torch.diag(Lambda) - p @ p.H) @ V.H, A.type(torch.complex64), atol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before getting to the full implementation, we are going to explain how we can perform autoregressive decoding.\n",
    "Indeed, when doing a convolution, we assume that the whole input in known. In autoregressive decoding it is not the cae anymore. We therefore have to get back to the basic definition of the state-space system.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent decoding\n",
    "The authors derived a computation of each step in $\\mathcal{O}(N)$ (instead of a naive $\\mathcal{O}(N^2))$, by leveraging the DPLR form of $\\bA$ with single unidimensional inputs, and $\\mathcal{O}(HN)$ with H-dimensional inputs and $N$ the polynomial space dimension.\n",
    "\n",
    "The authors derive that we can decompose $\\bAb$ as the product of two DPLR matrices:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\bAb = \\bA_1 \\bA_0,\n",
    "\\end{equation}\n",
    "with:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\bA_i = \\bLa_i - \\bp_i \\bq_i^*.  \n",
    "\\end{equation}\n",
    "where:\n",
    "\\begin{cases}\n",
    "    \\bLa_0 &= 2 + \\bLa,\\\\\n",
    "    \\bp_0 &= \\bp,\\\\\n",
    "    \\bq_0 &= \\bp.\n",
    "\\end{cases}\n",
    "and:\n",
    "\\begin{cases}\n",
    "    \\bLa_1 &= (2 - \\bLa)^{-1},\\\\\n",
    "    \\bp_1 &= \\bLa_1(1 + \\bp^* \\bLa_1 \\bp)^{-1},\\\\\n",
    "    \\bq_1 &= \\bp^* \\bLa_1\n",
    "\\end{cases}\n",
    "\n",
    "\n",
    "Below is the values of the matrices computed in the original paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_dplr(Lambda, p, b, step=1.):\n",
    "    # Convert parameters to matrices\n",
    "    N = Lambda.shape[0]\n",
    "    A = torch.diag(Lambda) - p @ p.H\n",
    "    I = torch.eye(N)\n",
    "\n",
    "    # Forward Euler\n",
    "    A_0 = (2.0 / step) * I + A\n",
    "\n",
    "    # Backward Euler\n",
    "    D = torch.diag(1.0 / ((2.0 / step) - Lambda))\n",
    "    D_p = D @ p\n",
    "\n",
    "    \n",
    "    A_1 = D - (D_p * (1.0 / (1 + (p.H @ D_p))) * p.H @ D)\n",
    "\n",
    "    # A bar and b bar\n",
    "    A_bar = A_1 @ A_0\n",
    "    b_bar = 2 * A_1 @ b\n",
    "\n",
    "    return A_bar, b_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.randn(N, 1)\n",
    "b = torch.randn(N, 1)\n",
    "Lambd = torch.randn(N)\n",
    "\n",
    "# Our new formula\n",
    "A_bar_dplr, b_bar_dplr = discrete_dplr(Lambd, p, b)\n",
    "\n",
    "# Base formula\n",
    "A = torch.diag(Lambd) - p @ p.H\n",
    "A_bar_closed_form, b_bar_closed_form = discretize(A, b)\n",
    "\n",
    "assert torch.allclose(A_bar_dplr, A_bar_closed_form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can perform autoregressice decoding easily, simply by using our matrices $\\bA_0, \\ \\bA_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_ssm(A_bar, b_bar, c, u, x_0):\n",
    "    def step(x_k_1, u_k):\n",
    "        x_k = A_bar @ x_k_1 + b_bar @ u_k\n",
    "        y_k = c.H @ x_k\n",
    "        return x_k, y_k\n",
    "    recurrence = []\n",
    "    x_k = x_0\n",
    "    for i in range(u.shape[0]):\n",
    "        x_k, y_k = step(x_k, u[i])\n",
    "        recurrence.append(y_k)\n",
    "    return x_k, torch.tensor(recurrence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But with this form we do not leverage the efficiency of DPLR matrices. Indeed, the matrix-vector product of a DPLR matrix is $\\mathcal{O}(N)$.\n",
    "Indeed:\n",
    "\n",
    "\\begin{equation}\n",
    "    (\\bLa - \\bp \\bq^*)\\bx = \\bLa \\bx - \\bp \\underbrace{(\\bq^* \\bx)}_{scalar}.\n",
    "\\end{equation}\n",
    "\n",
    "To code this, we are simple going to need the DPLR decomposition and not the full matrix anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_dplr_opti(Lambda, p, b, step=1):\n",
    "    \"\"\"DPLR of A_0 and A_1.\"\"\"\n",
    "    Lambda_0 = 2. / step + Lambda[:, None]\n",
    "    p_0 = p\n",
    "    q_0 = p\n",
    "    \n",
    "    Lambda_1 = 1. / ((2. / step) - Lambda[:, None])\n",
    "    p_1 = Lambda_1 * p * 1. / (1. + p.H @ (Lambda_1 * p))\n",
    "    q_1 = Lambda_1.conj() * p\n",
    "    \n",
    "    b_bar = 2 * (Lambda_1 * b - p_1 * (q_1.H @ b))\n",
    "\n",
    "    return (Lambda_0, p_0, q_0), (Lambda_1, p_1, q_1), b_bar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dplr_vector_product(dplr, x):\n",
    "    \"\"\"Unidimensionnal optimized dplr matrix-vector product.\"\"\"\n",
    "    Lambda, p, q = dplr\n",
    "    diagonal_prod = Lambda * x\n",
    "\n",
    "    lr_prod = p * (q.H @ x)\n",
    "    \n",
    "    return diagonal_prod - lr_prod\n",
    "\n",
    "\n",
    "def scan_ssm_opti(dplr_0, dplr_1, b_bar, c, u, x_0):\n",
    "    \"\"\"Optimized RNN computations.\"\"\"\n",
    "    def step(x_k_1, u_k):\n",
    "        x_k = dplr_vector_product(dplr_0, x_k_1)\n",
    "        x_k = dplr_vector_product(dplr_1, x_k) + b_bar * u_k\n",
    "        y_k = c.H @ x_k\n",
    "\n",
    "        return x_k, y_k\n",
    "    \n",
    "    recurrence = []\n",
    "    x_k = x_0\n",
    "    for i in range(u.shape[0]):\n",
    "        x_k, y_k = step(x_k, u[i])\n",
    "        recurrence.append(y_k)\n",
    "    return x_k, torch.tensor(recurrence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do a big check, to see if everything is coherent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_conversion(N=8, L=16):\n",
    "    V, Lambda, p, b = hippo_matrices_dplr(N)\n",
    "    \n",
    "    # Compute A in closed form\n",
    "    A = torch.diag(Lambda) - p @ p.H\n",
    "    c_base = torch.randn(N, 1)\n",
    "    \n",
    "    # Change the basis of c.\n",
    "    c = V.H @ c_base.type(torch.complex64)\n",
    "    A_bar, b_bar = discretize(A, b)\n",
    "    c_tilde = compute_c_tilde(A_bar, c, L)\n",
    "\n",
    "    # CNN form.\n",
    "    K = kernel_dplr(Lambda, p, b, c_tilde, L)\n",
    "\n",
    "    # Simple RNN form.\n",
    "    K_simple = kernel_simple(A_bar, b_bar, c, L=L)\n",
    "    assert torch.allclose(K, K_simple, atol=1e-4)\n",
    "    \n",
    "    # New RNN form\n",
    "    A_bar_new, b_bar_new = discrete_dplr(Lambda, p, b)\n",
    "    K_rnn = kernel_simple(A_bar, b_bar, c, L=L)\n",
    "    assert torch.allclose(K_simple, K_rnn, atol=1e-4)\n",
    "    \n",
    "\n",
    "    # Apply CNN\n",
    "    u = torch.arange(L).type(torch.complex64)\n",
    "    y_1 = causal_convolution(u, K)\n",
    "\n",
    "    # Apply RNN\n",
    "    _, y_2 = scan_ssm(\n",
    "        A_bar, b_bar, c, u[:, None], torch.zeros((N,)).type(torch.complex64)\n",
    "    )\n",
    "    assert torch.allclose(y_1, y_2.reshape(-1), atol=1e-4, rtol=1e-4)\n",
    "    \n",
    "    # Optimized RNN form\n",
    "    dplr_0, dplr_1, b_bar_opti = discrete_dplr_opti(Lambda, p, b)\n",
    "\n",
    "    assert torch.allclose(b_bar, b_bar_opti)\n",
    "    \n",
    "    _, y_2_opti = scan_ssm_opti(dplr_0, dplr_1, b_bar_opti, c, u[:, None], torch.zeros((N, 1)).type(torch.complex64))\n",
    "    assert torch.allclose(y_1, y_2_opti.reshape(-1), atol=1e-4, rtol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_conversion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are almost done. We now need to adapt it to handle multidimensional inputs, as well as a batch dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_dplr_opti_multi(Lambda, p, b, step=1):\n",
    "    \"\"\"DPLR of A_0 and A_1 with multidimensionnal data.\"\"\"\n",
    "    \n",
    "    # Lambda (H, N)\n",
    "    # p, b (H, N)\n",
    "    Lambda_0 = 2. / step + Lambda\n",
    "    p_0 = p\n",
    "    q_0 = p\n",
    "    \n",
    "    Lambda_1 = 1. / ((2. / step) - Lambda)\n",
    "    p_1 = Lambda_1 * p * 1. / (1. + (p.conj() * Lambda_1 * p).sum(axis=-1, keepdim=True))\n",
    "    q_1 = Lambda_1.conj() * p\n",
    "    \n",
    "    b_bar = 2 * (Lambda_1 * b - p_1 * (q_1.conj() * b).sum(axis=-1, keepdim=True))\n",
    "\n",
    "    return (Lambda_0, p_0, q_0), (Lambda_1, p_1, q_1), b_bar\n",
    "\n",
    "def dplr_vector_product_multi(dplr, x):\n",
    "    # x (B, H, N)\n",
    "    # Lambda (H, N)\n",
    "    # p, q (H, N)\n",
    "    \n",
    "    Lambda, p, q = dplr\n",
    "    diagonal_prod = Lambda[None, :, :] * x\n",
    "    lr_prod = p[None, :, :] * (q[None, :, :].conj() * x).sum(axis=2, keepdims=True)\n",
    "    \n",
    "    return diagonal_prod - lr_prod\n",
    "\n",
    "def dplr_vector_prod_multi_simple(dplr, x):\n",
    "    \"\"\"Naive version of dplr matrix-vector product.\"\"\"\n",
    "    out = torch.zeros_like(x)\n",
    "    Lambda, p, q = dplr\n",
    "    for i in range(x.shape[0]):\n",
    "        for h in range(x.shape[1]):\n",
    "            prod = dplr_vector_product((Lambda[h][:, None], p[h][:, None], q[h][:, None]), x[i, h][:, None]).view(-1)\n",
    "            out[i, h] = prod\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dplr_random(N):\n",
    "    Lambda = torch.randn(N, 1)\n",
    "    p = torch.randn(N, 1)\n",
    "    q = torch.randn(N, 1)\n",
    "    \n",
    "    return Lambda, p, q\n",
    "\n",
    "def make_dplr_random_multi(H, N):\n",
    "    Lambda = torch.randn(H, N)\n",
    "    p = torch.randn(H, N)\n",
    "    q = torch.randn(H, N)\n",
    "    \n",
    "    return Lambda, p, q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 3\n",
    "N = 5\n",
    "x = torch.randn(8, H, N)\n",
    "Lambda, p, q = make_dplr_random_multi(H, N)\n",
    "dplr = Lambda, p, q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if our vectorized dplr matrix vector product works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dplr_prod = dplr_vector_product_multi(dplr, x)\n",
    "dplr_prod_simple = dplr_vector_prod_multi_simple(dplr, x)\n",
    "\n",
    "assert torch.allclose(dplr_prod, dplr_prod_simple, atol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_ssm_opti_multi(dplr_0, dplr_1, b_bar, c, u, x_0):\n",
    "    # b_bar (H, N)\n",
    "    # c (H, N)\n",
    "    # u (B, H, L)\n",
    "    # x_0 (B, H, N)\n",
    "    \n",
    "    def step(x_k_1, u_k):\n",
    "        x_k = dplr_vector_product_multi(dplr_0, x_k_1)\n",
    "\n",
    "        x_k = dplr_vector_product_multi(dplr_1, x_k) + b_bar[None, :, :] * u_k[:, :, None]\n",
    "        y_k = (c[None, :, :].conj() * x_k).sum(axis=-1, keepdim=True)\n",
    "\n",
    "        return x_k, y_k\n",
    "    recurrence = []\n",
    "    x_k = x_0\n",
    "    for i in range(u.shape[-1]):\n",
    "        x_k, y_k = step(x_k, u[:, :, i])\n",
    "        recurrence.append(y_k)\n",
    "\n",
    "    return x_k, torch.cat(recurrence, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_ssm_opti_multi_simple(dplr_0, dplr_1, b_bar, c, u, x_0):\n",
    "    \"\"\"Naive version of scan ssm multi.\"\"\"\n",
    "    Lambda_0, p_0, q_0 = dplr_0\n",
    "    Lambda_1, p_1, q_1 = dplr_1\n",
    "    \n",
    "    batch_size = u.shape[0]\n",
    "    hidden_size = u.shape[1]\n",
    "    \n",
    "    out = torch.zeros_like(u)\n",
    "    for i in range(batch_size):\n",
    "        for h in range(hidden_size):\n",
    "            dplr_h_0 = Lambda_0[h][:, None], p_0[h][:, None], q_0[h][:, None]\n",
    "            dplr_h_1 = Lambda_1[h][:, None], p_1[h][:, None], q_1[h][:, None]\n",
    "            out[i, h] = scan_ssm_opti(dplr_h_0, dplr_h_1, b_bar[h][:, None], c[h][:, None], u[i, h][:, None], x_0[i, h][:, None])[-1]\n",
    "    return None, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 5\n",
    "N = 10\n",
    "B = 4\n",
    "L = 3\n",
    "dplr_0 = make_dplr_random_multi(H, N)\n",
    "dplr_1 = make_dplr_random_multi(H, N)\n",
    "x_0 = torch.zeros(B, H, N)\n",
    "u = torch.randn(B, H, L)\n",
    "b_bar = torch.randn(H, N)\n",
    "c = torch.randn(H, N)\n",
    "\n",
    "_, scan_simple = scan_ssm_opti_multi_simple(dplr_0, dplr_1, b_bar, c, u, x_0)\n",
    "_, scan = scan_ssm_opti_multi(dplr_0, dplr_1, b_bar, c, u, x_0)\n",
    "\n",
    "assert torch.allclose(scan, scan_simple, atol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_conversion_multi(B=4, H=10, N=8, L=5):\n",
    "    V, Lambda, p, b = hippo_matrices_dplr(N)\n",
    "    \n",
    "    # Compute A in closed form.\n",
    "    A = torch.diag(Lambda) - p @ p.H\n",
    "    \n",
    "    # Make H copies of A, p, b, Lambda.\n",
    "    A = A.expand(H, N, N).clone()\n",
    "    p = p.squeeze().expand(H, N).clone()\n",
    "    b = b.squeeze().expand(H, N).clone()\n",
    "    Lambda = Lambda.squeeze().expand(H, N).clone()\n",
    "    \n",
    "    # Initialize H c.\n",
    "    c_base = torch.randn(H, N)\n",
    "    \n",
    "    # Change the basis of c.\n",
    "    c = V.H @ c_base[:, :, None].type(torch.complex64)\n",
    "    c = c.view(H, N)\n",
    "    \n",
    "    # Get A_bar (needed for c_tilde).\n",
    "    A_bar, b_bar = discretize_multi(A, b)\n",
    "    \n",
    "    \n",
    "    # Compute c_tilde\n",
    "    c_tilde = compute_c_tilde_multi(A_bar, c, L)\n",
    "\n",
    "    # CNN form. Check again if our vectorized computations give the same result as a naive one.\n",
    "    K = kernel_dplr_multi(Lambda, p, b, c_tilde, L)\n",
    "    K_simple = kernel_dplr_multi_simple(Lambda, p[:, :, None], b[:, :, None], c_tilde[:, :, None], L)\n",
    "    \n",
    "    assert torch.allclose(K, K_simple, atol=1e-4)\n",
    "    \n",
    "    # Create an input signal with a batch size, a hidden size and a sequence length.\n",
    "    \n",
    "    u = torch.randn(B, H, L).type(torch.complex64)\n",
    "    \n",
    "    # Apply CNN\n",
    "    y_cnn = causal_convolution_multi(u, K)\n",
    "\n",
    "    # Apply RNN\n",
    "    # Optimized RNN form\n",
    "    dplr_0, dplr_1, b_bar_opti = discrete_dplr_opti_multi(Lambda, p, b)\n",
    "    \n",
    "    # Check if we obtain the same b_bar than with the closed form formula.\n",
    "    assert torch.allclose(b_bar, b_bar_opti)\n",
    "    \n",
    "    # Apply RNN autoregressively,\n",
    "    _, y_rnn = scan_ssm_opti_multi(\n",
    "        dplr_0, dplr_1, b_bar_opti, c, u, torch.zeros((N,)).type(torch.complex64)\n",
    "    )\n",
    "    \n",
    "    # Compare with CNN output.\n",
    "    assert torch.allclose(y_cnn, y_rnn, atol=1e-4, rtol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_conversion_multi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done! We now have everything to implement our model within a Pytorch module."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-s4",
   "language": "python",
   "name": "env-s4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "a263f42c39b2fd75b37cb89946a27f6140cd004b337ff228565a862a637fff96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
