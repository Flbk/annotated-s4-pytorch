{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\RR}{\\mathbb{R}}\n",
    "\\newcommand{\\ZZ}{\\mathbb{Z}}\n",
    "\\newcommand{\\CC}{\\mathbb{C}}\n",
    "\\newcommand{\\EE}{\\mathbb{E}}\n",
    "\\newcommand{\\Zz}{\\mathcal{Z}}\n",
    "\\newcommand{\\Ww}{\\mathcal{W}}\n",
    "\\newcommand{\\Vv}{\\mathcal{V}}\n",
    "\\newcommand{\\Nn}{\\mathcal{N}}\n",
    "\\newcommand{\\NN}{\\mathcal{N}}\n",
    "\\newcommand{\\Hh}{\\mathcal{H}}\n",
    "\\newcommand{\\Bb}{\\mathcal{B}}\n",
    "\\newcommand{\\Ee}{\\mathcal{E}}\n",
    "\\newcommand{\\Cc}{\\mathcal{C}}\n",
    "\\newcommand{\\Gg}{\\mathcal{G}}\n",
    "\\newcommand{\\Ss}{\\mathcal{S}}\n",
    "\\newcommand{\\Pp}{\\mathcal{P}}\n",
    "\\newcommand{\\Ff}{\\mathcal{F}}\n",
    "\\newcommand{\\Xx}{\\mathcal{X}}\n",
    "\\newcommand{\\Mm}{\\mathcal{M}}\n",
    "\\newcommand{\\Ii}{\\mathcal{I}}\n",
    "\\newcommand{\\Dd}{\\mathcal{D}}\n",
    "\\newcommand{\\Ll}{\\mathcal{L}}\n",
    "\\newcommand{\\Tt}{\\mathcal{T}}\n",
    "\\newcommand{\\al}{\\alpha}\n",
    "\\newcommand{\\la}{\\lambda}\n",
    "\\newcommand{\\ga}{\\gamma}\n",
    "\\newcommand{\\Ga}{\\Gamma}\n",
    "\\newcommand{\\La}{\\Lambda}\n",
    "\\newcommand{\\si}{\\sigma}\n",
    "\\newcommand{\\Si}{\\Sigma}\n",
    "\\newcommand{\\be}{\\beta}\n",
    "\\newcommand{\\de}{\\delta}\n",
    "\\newcommand{\\De}{\\Delta}\n",
    "\\renewcommand{\\phi}{\\varphi}\n",
    "\\renewcommand{\\th}{\\theta}\n",
    "\\newcommand{\\om}{\\omega}\n",
    "\\newcommand{\\Om}{\\Omega}\n",
    "\\newcommand{\\eps}{\\varepsilon}\n",
    "\\newcommand{\\bo}[1]{\\boldsymbol{\\mathbf{#1}}}\n",
    "\\newcommand{\\bu}{\\bo{u}}\n",
    "\\newcommand{\\bv}{\\bo{v}}\n",
    "\\newcommand{\\bC}{\\bo{C}}\n",
    "\\newcommand{\\bp}{\\bo{p}}\n",
    "\\newcommand{\\bq}{\\bo{q}}\n",
    "\\newcommand{\\bX}{\\bo{X}}\n",
    "\\newcommand{\\bc}{\\bo{c}}\n",
    "\\newcommand{\\bb}{\\bo{b}}\n",
    "\\newcommand{\\bh}{\\bo{h}}\n",
    "\\newcommand{\\by}{\\bo{y}}\n",
    "\\newcommand{\\lc}{\\bo{L}(\\bC)}\n",
    "\\newcommand{\\lcb}[1]{\\bo{L}(\\bo{#1})}\n",
    "\\newcommand{\\ba}{\\bo{a}}\n",
    "\\newcommand{\\bbv}{\\bo{b}}\n",
    "\\newcommand{\\tD}{\\bo{\\widetilde{D}}}\n",
    "\\newcommand{\\tLa}{\\bo{\\widetilde{\\La}}}\n",
    "\\newcommand{\\tCbe}{\\bo{\\widetilde{C}^{\\be}}}\n",
    "\\newcommand{\\bbe}{\\bo{\\beta}}\n",
    "\\newcommand{\\Cbe}{\\bC^{\\bbe}}\n",
    "\\newcommand{\\bhat}{\\bo{\\hat{\\be}}}\n",
    "\\newcommand{\\pibe}{\\bpi^{\\bbe}}\n",
    "\\newcommand{\\bD}{\\bo{D}}\n",
    "\\newcommand{\\bZ}{\\bo{Z}}\n",
    "\\newcommand{\\bF}{\\bo{F}}\n",
    "\\newcommand{\\bA}{\\bo{A}}\n",
    "\\newcommand{\\bB}{\\bo{B}}\n",
    "\\newcommand{\\bK}{\\bo{K}}\n",
    "\\newcommand{\\bI}{\\bo{I}}\n",
    "\\newcommand{\\bS}{\\bo{S}}\n",
    "\\newcommand{\\bLa}{\\bo{\\La}}\n",
    "\\newcommand{\\ctilde}{\\bo{\\tilde{c}}}\n",
    "\\newcommand{\\bhatK}{\\bo{\\hat{K}}}\n",
    "\\newcommand{\\bR}{\\bo{R}}\n",
    "\\newcommand{\\bAb}{\\bo{\\bar{A}}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S4 in Pytorch.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook aims at explaining the S4 layer described in [S4](https://arxiv.org/abs/2111.00396), with more details on practical use cases, as well as a simple Pytorch implementation.\n",
    "Some parts of this code are directly coming from the excellent guide [Annotated S4](https://srush.github.io/annotated-s4/).\n",
    "\n",
    "The goal of the notebook is to be as concise as possible while providing enough details for a full comprehension of a practical implementation of S4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelisation\n",
    "\n",
    "### Classical approaches\n",
    "\n",
    "Deep NLP has made huge progress since the arrival of the sequence-to-sequence models. A sequence-to-sequence model is a model that maps a sequence $u_0, \\dots, u_{L-1}$ to another sequence $y_0, \\dots, y_{L-1}$.\n",
    "\n",
    "The main approaches in NLP were first RNN, that mimics Hidden Markov Process. In simple terms, a RNN models a situation recursively:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\begin{cases}\n",
    "        h_{k+1} &=& g(u_{k+1}, h_k),\\\\\n",
    "        y_{k+1} &=& f(h_{k+1}).\n",
    "    \\end{cases}\n",
    "\\end{equation}\n",
    "where $h_k$ represents a hidden state. Here each output $y_k$ is built recursively on the precedent value $h_{k-1}$. The main drawbacks of such models is that it is extremely difficult control how the information of previous steps flows up to the current step. It has even been derived that statistically such networks doesn't have long-memory (i.e the output at step $k$ is unlikely to have retained information of $u_{k-l}$if $l$ is large enough).\n",
    "\n",
    "The other and currently SOTA architecture is the transformer.\n",
    "\n",
    "Transformers are extremelly powerful because the output sequence depends directly on *all* the previous steps:\n",
    "\n",
    "\\begin{equation}\n",
    "    y_{k+1} = \\sum_{i=0}^{k} f(u_i, u_{k+1}).\n",
    "\\end{equation}\n",
    "\n",
    "Therefore they do have long-memory. But here the problem comes form the memory consumption of such operation. To process a full sequence the memory complexity is $\\mathcal{O}(L^2)$.\n",
    "\n",
    "### State-space approach\n",
    "\n",
    "To overcome these problems, S4 introduces the formalism of state-space models. Here $u_k \\in \\RR$ is a scalar input.\n",
    "\n",
    "\\begin{equation}\\label{eq:state-space}\n",
    "    \\begin{cases}\n",
    "        x_{k+1} = \\bA x_k + \\bb u_k,\\\\\n",
    "        y_{k+1} = \\bc^T x_{k+1}.\n",
    "    \\end{cases}\n",
    "\\end{equation}\n",
    "where $x_k \\in \\RR^N$ is a vector and obviously $\\bc \\in \\RR^N$. For multidimensionnal inputs, we simply apply these steps (with the same parameters) independently to all coordinates.\n",
    "\n",
    "Let's write a first implementation of such a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseSSM:\n",
    "    def __init__(self, A, b, c):\n",
    "        self.A = A\n",
    "        self.b = b\n",
    "        self.c = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSSM(BaseSSM):\n",
    "    def __call__(self, u, L):\n",
    "\n",
    "        y = torch.zeros(L)\n",
    "        x_k = 0\n",
    "        for i in range(L):\n",
    "            x_k += b * u[i]\n",
    "            y_k = self.c.T @ x_k\n",
    "            y[i] = y_k\n",
    "            x_k = self.A @ x_k\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "L = 8\n",
    "\n",
    "A = torch.randn(N, N)\n",
    "b = torch.rand(N, 1)\n",
    "c = torch.rand(N, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_ssm = SimpleSSM(A, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc7a39d4be0>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_interval = torch.arange(L)\n",
    "u = torch.sin(2 * torch.pi * torch.arange(L) / L)\n",
    "plt.plot(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc7a38301c0>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = simple_ssm(u, L)\n",
    "plt.plot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State-space computations\n",
    "\n",
    "Now let's take a step back and remember that our goal is to train a model, whose parameters will include $\\bA, \\bb, \\bc$.\n",
    "\n",
    "However if the formulation of \\eqref{eq:state-space} seems simple, it is in fact quite complicated for training, due do its recursive definition (same problems faced during training of RNN actually).\n",
    "\n",
    "A big advantage of transformers is the possibility to process in parallel the whole sequence, that greatly improves the training speed and the backpropagation of the gradient is more easy than with recursive architectures.\n",
    "\n",
    "Hence a legitimate question is: do we have the same property with S4? And the answer is yes!\n",
    "\n",
    "To explain it, we are now going to focus exclusively on training, i.e when the full input and output are already available. Later, we will explain how we can generate outputs in an autoregressive manner.\n",
    "\n",
    "## Training - Convolution view\n",
    "\n",
    "One can notice that if we unrol \\eqref{eq:state-space}, $y \\in \\RR^L$ can be directly expressed as a convolution between the input $u \\in \\RR^L$ and a filter $\\bK \\in \\RR^L$:\n",
    "\n",
    "\\begin{align}\n",
    "    y_0 &= \\bc^T\\bb u_0,  \\dots),\\\\\n",
    "    y_1 &= \\bc^T\\bA\\bb u_0 + \\bc^T\\bb u_1,\\\\\n",
    "    y_2 &= \\bc^T \\bA^2 \\bb u_0 + \\bc^T\\bA\\bb u_1 + \\bc^T\\bb u_2,\\\\\n",
    "    \\vdots\\\\\n",
    "    y_k &= \\sum_{i=0}^k \\bc^T\\bA^i\\bb u_{k - i}.\n",
    "\\end{align}\n",
    "\n",
    "We have therefore: $y = \\bK * u$, with $\\bK = \\left(\\bc^T \\bb, \\bc^T\\bA\\bb, \\dots, \\bc^T\\bA^{L-1}\\bb\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good news: a convolution can be computed in $\\mathcal{O}(L \\log L)$ once the filter $\\bK$ is known, using Discrete Fourier Transform (with padding to avoid circular convolution).\n",
    "\n",
    "Compared to the quadratic complexity of transformers, we have a huge gain in term of memory usage.\n",
    "\n",
    "Let's write a first function to see what it gives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_simple(A, b, c, L):\n",
    "    K = [(c.T @ A.matrix_power(l) @ b).item() for l in range(L)]\n",
    "    \n",
    "    # We take the real part because later we will use complex numbers.\n",
    "    # But because K depends only on real values matrices, it should be real (up to floating point error on the imaginary part).\n",
    "    return torch.tensor(K).real\n",
    "\n",
    "def causal_convolution(u, K):\n",
    "    convolution_shape = u.shape[0] + K.shape[0]\n",
    "    \n",
    "    # Specifying the paramter 'n' will automatically pad our vectors to the right dimension.\n",
    "    u_fft = torch.fft.fft(u, n=convolution_shape)\n",
    "    K_fft = torch.fft.fft(K, n=convolution_shape)\n",
    "    out = u_fft * K_fft\n",
    "    return torch.fft.ifft(out).real[: u.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConvSSM(BaseSSM):\n",
    "    \n",
    "    def __call__(self, u, L):\n",
    "    \n",
    "        K = k_simple(self.A, self.b, self.c, L)\n",
    "        y = causal_convolution(u, K)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_conv_ssm = SimpleConvSSM(A, b, c)\n",
    "y_conv = simple_conv_ssm(u, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(y, y_conv, atol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the main bottleneck of this computation is how we obtain the convolution kernel. We exponentiate a matrix $L$ times, compute a lot of matrix products etc, which is highly non efficient and non stable from a numerical point of view.\n",
    "\n",
    "To make this more efficient, we can find more sophisticated algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Namely, instead of computing directly $\\bK$, we are going to compute its DFT, $\\bhatK$ and then simply apply a inverse Fourier Transform (IDFT). Let $\\om_k = \\exp\\left(-{\\dfrac{2i \\pi k}{N}}\\right)$.\n",
    "\n",
    "\\begin{align}\n",
    "    \\bhatK_k &= \\sum_{i=0}^{L-1} \\bK_i \\omega_k^i,\\\\\n",
    "    &= \\sum \\bc^T A^i b \\omega_k^i,\\\\\n",
    "    &= \\bc^T \\left(\\sum \\bA^i \\omega_k^i \\right) \\bb,\\\\\n",
    "    &= \\bc^T (\\bI - \\bA^L)(\\bI - \\bA\\omega_k)^{-1} \\bb.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this does not really reduce the complexity, because now we have to compute an inverse $L$ times (for each $\\om_k$), giving a complexity of $\\mathcal{O}(LN^3)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HiPPO matrix\n",
    "\n",
    "TLDR: we can assume that $\\bA$ is similar to a matrix of the form $\\bLa - \\bp^* \\bp$, where we now considerate matrix and vectors with coefficients in $\\CC$.\n",
    "\n",
    "Where $\\bLa \\in \\CC^{N \\times N}$ is diagonal and $\\bp \\in \\CC^{N \\times 1}$.\n",
    "$.^*$ designated the hermitian adjoint (= transpose + conjugate) of a matrix (a vector is viewed as a matrix of $\\CC^{N \\times 1}$).\n",
    "\n",
    "This decomposition is called Diagonal Plus Low Rank (DPLR).\n",
    "\n",
    "*Remark:* In the original article the derivations are made with $\\bA \\sim \\bLa + \\bq^* \\bp$. But in practice in S4 we use $\\bp = \\bq$ which is valid and works better for numerical reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, the matrix $A$ we are using can be decomposed in the following form:\n",
    "\\begin{equation}\n",
    "    \\bA = - \\dfrac{1}{2}\\bI - \\bS - \\bp^*\\bp,\n",
    "\\end{equation}\n",
    "where $\\bS$ is a skew-hermitian matrix ($\\bS = - \\bS^*$), and $\\bp \\in \\RR^{N}$ is a vector of dimension 1.\n",
    "\n",
    "And in the adapted basis, the inverse of a DLPR matrix is much more easy to compute, thanks to the Woodburry inversion formula:\n",
    "\n",
    "\\begin{equation}\n",
    "    (\\bLa - \\bp^* \\bq)^{-1} = \\bLa^{-1} + \\bLa^{-1}\\bp \\left(1 - \\bq^*\\bLa^{-1} \\bp\\right)^{-1}\\bq^* \\bLa^{-1}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we apply this result to the expression of $\\bhatK$, with some more algebraic operations, we obtain a quite simple formula for its expression:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\bhatK_k = \\dfrac{2}{1 + \\om_k}\\left[\\ctilde^* \\bR_k \\bb - \\ctilde^* \\bR_k \\bp (1 + \\bp^*\\bR_k \\bp)^{-1}\\bp^*\\bR_k \\bb\\right].\n",
    "\\end{equation}\n",
    "\n",
    "with $\\bR_k = \\left(2\\dfrac{1 - \\om_k}{1 + \\om_k} - \\bLa \\right)^{-1}$ and $\\ctilde^* = \\bc^* (\\bI - \\bAb^L)$.\n",
    "\n",
    "And here, in fact all the matrix multiplications can be evaluated very efficiently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\\label{eq:cauchy-K}\n",
    "   \\ctilde^T \\bR_k \\bb &= \\sum_{i=1}^{N} \\dfrac{\\ctilde_i \\bb_i}{\\om_k - \\bLa_i},\n",
    "\\end{align}\n",
    "\n",
    "and because we want to compute it for all $\\om_k$, the complexity reduces to $\\mathcal{O}(NL)$.\n",
    "In fact, we can be even more efficient, be we need to rely on algorithms that are not yet implemented on Pytorch.\n",
    "But notice that this complexity is not a bottleneck when the biggest memory cost comes from the size of the sequence.\n",
    "\n",
    "Computing operation \\eqref{eq:cauchy-K} for all $k$ is actually a Cauchy product, a well studied problem in the litterature. We are going to implement it in a naive way, but again it won't be the main bottleneck of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_c_tilde(A, c):\n",
    "    return c.T @ (torch.eye(Lambd.shape[0]) - A.matrix_power(L))\n",
    "\n",
    "def cauchy(p, q, lambd, omega_L):\n",
    "    omega_L = 2. * ((1. - omega_L) / (1 + omega_L))\n",
    "    dot_product = p * q\n",
    "    lambd = lambd[:, None]\n",
    "    omega_L = omega_L[None, :]\n",
    "    cauchy_product = dot_product / (omega_L - lambd)\n",
    "    return cauchy_product.sum(axis=-2).view(-1)\n",
    "\n",
    "def kernel_dplr(Lambd, p, b, c_tilde, L):\n",
    "    omega_L = torch.exp((-2j * torch.pi) * torch.arange(L) / L)\n",
    "    term_1 = cauchy(b, c_tilde, lambd, omega_L)\n",
    "    term_2 = cauchy(c_tilde, p, lambd, omega_L)\n",
    "    term_3 = 1. / (1. + cauchy(p.conj(), p, lambd, omega_L))\n",
    "    term_4 = cauchy(p.conj(), b, lambd, omega_L)\n",
    "    \n",
    "    K_fft = (2. / (1. + omega_L)) * (term_1 - term_2 * term_3 * term_4) \n",
    "    return torch.fft.ifft(K_fft, L).real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lambd = torch.randn(N)\n",
    "p = torch.randn(N, 1)\n",
    "b = torch.randn(N, 1)\n",
    "c = torch.randn(N, 1)\n",
    "\n",
    "A = torch.diag(Lambd) - p @ p.H\n",
    "\n",
    "\n",
    "c_tilde = compute_c_tilde(A, c)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_dplr = kernel_dplr(Lambd, p, b, c_tilde) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientConvSSM(BaseSSM):\n",
    "    def __init__(self, Lambd, p, b, c):\n",
    "        self.Lambd = Lambd\n",
    "        self.p = p\n",
    "        self.b = b\n",
    "        self.c = c\n",
    "        \n",
    "\n",
    "        \n",
    "    def __call__(u, L):\n",
    "        A = self.Lambd + p @ p.H\n",
    "        c_tilde = compute_c_tilde(A, c)\n",
    "        K = kernel_dplr(self.Lambd, p, b, c_tilde)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hippo_init(N):\n",
    "    u = torch.arange(N)\n",
    "    b = torch.sqrt(2 * u[:, None] + 1)\n",
    "    A = b @ b.T\n",
    "    A = torch.tril(A, 0)\n",
    "    A = - (A - torch.diag(u))\n",
    "\n",
    "\n",
    "    return A, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, b = hippo_init(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hippo_init_dplr(N):\n",
    "    u = torch.arange(N)[:, None]\n",
    "    \n",
    "    p = torch.sqrt(u + 0.5)\n",
    "\n",
    "    # Extract the skew-hermitian part of A.\n",
    "    S = torch.tril(p @ p.T)\n",
    "    S = - S + S.T\n",
    "\n",
    "    # A small trick to make a skew-hermitian matrix a hermitian one.\n",
    "    hermitian_S = S * -1j\n",
    "    Lambda, V = torch.linalg.eigh(hermitian_S)\n",
    "\n",
    "    # Mutliplies back the eigenvalues by (1j)^-1 to retrieve the original eigenvalues of the skew-hermitian matrix.\n",
    "    # We have to add the real parts of the eigenvalues, coming for the 1/2*Id part of the decomposition. \n",
    "    Lambda = Lambda * 1j - 0.5\n",
    "\n",
    "    # Change of basis for b and p.\n",
    "    b = torch.sqrt(2 * u + 1)\n",
    "    b = V.H @ b.type(torch.complex64)\n",
    "    p = V.H @ p.type(torch.complex64)\n",
    "    \n",
    "    return V, Lambda, p, b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "V, Lambda, p, b = hippo_init_dplr(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(V @ (torch.diag(Lambda) - p @ p.H) @ V.H, A.type(torch.complex64), atol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution\n",
    "\n",
    "The naive way to make the convolution would be the following one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "L = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.randn(N, N)\n",
    "c = torch.randn(N, 1)\n",
    "b = torch.randn(N, 1)\n",
    "u = torch.randn(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = k_conv(A, b, c, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  4.8000,   7.1977,  32.7416,   3.7354, 233.8863])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causal_convolution(u, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the main bottleneck of this computation is how we obtain the convolution kernel, because we are exponentiating a matrix L time, compute a lot of matrix products etc, which is highly non efficient.\n",
    "\n",
    "To make this more efficient, we can find more sophisticated algorithms.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Namely, instead of computing directly $\\bK$, we are going to compute its spectrum, $\\hat{\\bK}$ and then simply apply a inverse Fourier Transform (IDFT). Let $\\om_k = \\exp\\left(-{\\dfrac{2i \\pi k}{N}}\\right)$.\n",
    "\n",
    "\\begin{align}\n",
    "    \\hat{\\bK}_k &= \\sum_{i=0}^{L-1} \\bK_i \\omega_k^i,\\\\\n",
    "    &= \\sum \\bc^T A^i b \\omega_k^i,\\\\\n",
    "    &= \\bc^T \\left(\\sum \\bA^i \\omega_k^i \\right) \\bb,\\\\\n",
    "    &= \\bc^T (\\bI - \\bA^L)(\\bI - \\bA\\omega_k)^{-1} \\bb.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this does not really reduce the complexity, because now we have to compute an inverse $L$ times (for each $\\om_k$), giving a complexity of $\\mathcal{O}(LN^3)$.\n",
    "\n",
    "\n",
    "However, we are lucky because we are in fact dealing with matrices that have a special form: diagonal + low-rank.\n",
    "\n",
    "Indeed, the matrix $A$ we are using can be decomposed in the following form:\n",
    "\\begin{equation}\n",
    "    \\bA = - \\dfrac{1}{2}\\bI - \\bS - \\bp^*\\bp,\n",
    "\\end{equation}\n",
    "where $\\bS$ is a skew-hermitian matrix ($\\bS = - \\bS^*$), and $\\bp \\in \\RR^{N}$ is a vector of dimension 1.\n",
    "\n",
    "And in the adapted basis, the inverse of a DLPR matrix is much more easy to compute, thanks to the Woodburry inversion formula:\n",
    "\n",
    "\\begin{equation}\n",
    "    (\\bLa - \\bp^* \\bq)^{-1} = \\bLa^{-1} + \\bLa^{-1}\\bp \\left(1 - \\bq^*\\bLa^{-1} \\bp\\right)^{-1}\\bq^* \\bLa^{-1}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we apply this result to the expression of $\\bhatK$, with some more algebraic operations, we obtain a quite simple formula for its expression:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\bhatK_k = \\dfrac{2}{1 + \\om_k}\\left[\\ctilde^* \\bR_k \\bb - \\ctilde^* \\bR_k \\bp (1 + \\bp^*\\bR_k \\bp)^{-1}\\bp^*\\bR_k \\bb\\right].\n",
    "\\end{equation}\n",
    "\n",
    "with $\\bR_k = \\left(2\\dfrac{1 - \\om_k}{1 + \\om_k} - \\bLa \\right)^{-1}$ and $\\ctilde^* = \\bc^* (\\bI - \\bAb^L)$.\n",
    "\n",
    "And here, in fact all the matrix multiplications can be evaluated very efficiently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "   \\ctilde^T \\bR_k \\bb &= \\sum_{i=1}^{N} \\dfrac{\\ctilde_i \\bb_i}{\\om_k - \\bLa_i},\n",
    "\\end{align}\n",
    "\n",
    "and because we want to compute it for all $\\om_k$, the complexity reduces to $\\mathcal{O}(NL)$.\n",
    "In fact, we can be even more efficient, be we need to rely on algorithms that are not yet implemented on Pytorch.\n",
    "But notice that this complexity is not a bottleneck when the biggest memory cost comes from the size of the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cauchy(p, q, lambd, omega_L):\n",
    "    omega_L = 2. * ((1. - omega_L) / (1 + omega_L))\n",
    "    dot_product = p * q\n",
    "    lambd = lambd[:, None]\n",
    "    omega_L = omega_L[None, :]\n",
    "    cauchy_product = dot_product / (omega_L - lambd)\n",
    "    return cauchy_product.sum(axis=-2).view(-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_dplr(lambd, b, c, p, L):\n",
    "    omega_L = torch.exp((-2j * torch.pi) * torch.arange(L) / L)\n",
    "    term_1 = cauchy(b, c.conj(), lambd, omega_L)\n",
    "    term_2 = cauchy(c.conj(), p, lambd, omega_L)\n",
    "    term_3 = 1. / (1. + cauchy(p.conj(), p, lambd, omega_L))\n",
    "    term_4 = cauchy(p.conj(), b, lambd, omega_L)\n",
    "    \n",
    "    K_fft = (2. / (1. + omega_L)) * (term_1 - term_2 * term_3 * term_4) \n",
    "    return torch.fft.ifft(K_fft, L).real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_gen_simple(A, b, c, L):\n",
    "    K = k_conv(A, b, c, L)\n",
    "    def gen(z):\n",
    "        return torch.sum(K *  z ** torch.arange(L))\n",
    "    return gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_gen_inverse(A, b, ct, L):\n",
    "    I = torch.eye(A.shape[0])\n",
    "    A_L = A.matrix_power(L)\n",
    "    return lambda z: (ct.H @ torch.linalg.inv(I - A * z) @ b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_from_gen(A, b, c, L, inv=False):\n",
    "    if not inv:\n",
    "        gen = k_gen_simple(A, b, c, L)\n",
    "    else:\n",
    "        gen = k_gen_inverse(A, b, c, L)\n",
    "    omega_L = torch.exp((-2j * torch.pi) * torch.arange(L) / L)\n",
    "    at_roots = torch.tensor([gen(z) for z in omega_L])\n",
    "    out = torch.fft.ifft(at_roots, L).reshape(L)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize(A, b, c, step=1):\n",
    "    I = torch.eye(A.shape[0])\n",
    "    b_left = torch.linalg.inv(I - (step / 2.0) * A)\n",
    "    A_bar = b_left @ (I + (step / 2.0) * A)\n",
    "    b_bar = (b_left * step) @ b\n",
    "    return A_bar, b_bar, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_conv_kernel(L=10, N=20):\n",
    "    \n",
    "    V, Lambda, p, b = hippo_init_dplr(N)\n",
    "    A = torch.diag(Lambda) - p @ p.H\n",
    "    c = torch.randn(N, 1).type(torch.complex64)\n",
    "    c_basis_diag = V.H @ c.type(torch.complex64)\n",
    "    A_bar, b_bar, c_bar = discretize(A, b, c_basis_diag)\n",
    "    c_tilde_h = c_bar.T @ (torch.eye(N) - A_bar.matrix_power(L))\n",
    "    c_tilde = c_tilde_h.H\n",
    "    K_simple = k_conv(A_bar, b_bar, c_bar, L)\n",
    "    K_efficient = kernel_dplr(Lambda, b, c_tilde, p, L)\n",
    "\n",
    "    assert torch.allclose(K_simple, K_efficient, atol=1e-4)\n",
    "    \n",
    "    u = torch.randn(L)\n",
    "    \n",
    "    y_simple = causal_convolution(u, K_simple)\n",
    "    y_efficient = causal_convolution(u, K_efficient)\n",
    "    assert torch.allclose(y_simple, y_efficient, atol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_conv_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multidimensional_input_simple(u, K):\n",
    "    out = torch.zeros_like(u)\n",
    "    for i in range(u.shape[0]):\n",
    "        for j in range(u.shape[-1]):\n",
    "            out[i, :, j] = causal_convolution(u[i, :, j], K)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def causal_convolution_n(u, K):\n",
    "    K = K[None, :, None]\n",
    "    fft_shape = u.shape[1] + K.shape[1]\n",
    "    u_fft = torch.fft.fft(u, n=fft_shape, axis=1)\n",
    "    K_fft = torch.fft.fft(K, n=fft_shape, axis=1)\n",
    "    out = u_fft * K_fft\n",
    "    return torch.fft.ifft(out, axis=1)[:, :u.shape[1], :].real\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_multidimensional_convolution(batch_size=8, seq_length=10, hidden_size=5):\n",
    "    u = torch.randn(batch_size, seq_length, hidden_size)\n",
    "    K = torch.randn(seq_length)\n",
    "    simple_conv = multidimensional_input_simple(u, K)\n",
    "    efficient_conv = causal_convolution_n(u, K)\n",
    "    assert torch.allclose(efficient_conv, simple_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_multidimensional_convolution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent decoding\n",
    "\n",
    "In a situation of unsupervised generation, we need to be able to compute the state space equation autoregressively.\n",
    "But hopefully, thanks to the parametrization of $\\bA$ as a NPLR matrix, we can compute a recurrence step in $\\mathcal{O}(NH)$ where $H$ is the hidden dimension and $N$ the polynomial space dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_dplr(Lambda, p, b, c, L, step=1.):\n",
    "    # Convert parameters to matrices\n",
    "    b = b\n",
    "\n",
    "    N = Lambda.shape[0]\n",
    "    A = torch.diag(Lambda) - p @ p.H\n",
    "    I = torch.eye(N)\n",
    "\n",
    "    # Forward Euler\n",
    "    A0 = (2.0 / step) * I + A\n",
    "\n",
    "    # Backward Euler\n",
    "    D = torch.diag(1.0 / ((2.0 / step) - Lambda))\n",
    "    Dp = D @ p\n",
    "    \n",
    "    A1 = D - (Dp * (1.0 / (1 + (p.H @ Dp))) * p.H @ D)\n",
    "\n",
    "    # A bar and B bar\n",
    "    A_bar = A1 @ A0\n",
    "    b_bar = 2 * A1 @ b\n",
    "\n",
    "    return A_bar, b_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_ssm(Ab, Bb, Cb, u, x0):\n",
    "    def step(x_k_1, u_k):\n",
    "        x_k = Ab @ x_k_1 + Bb @ u_k\n",
    "        y_k = Cb @ x_k\n",
    "        return x_k, y_k\n",
    "    recurrence = []\n",
    "    x_k = x0\n",
    "    for i in range(u.shape[0]):\n",
    "        x_k, y_k = step(x_k, u[i])\n",
    "        recurrence.append(y_k)\n",
    "    return x_k, torch.tensor(recurrence).real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_conversion(N=8, L=16):\n",
    "    V, Lambda, p, b = hippo_init_dplr(N)\n",
    "    A = torch.diag(Lambda) - p @ p.H\n",
    "    c = torch.randn(N, 1).type(torch.complex64)\n",
    "    c_basis_diag = V.H @ c.type(torch.complex64)\n",
    "    A_bar, b_bar, c_bar = discretize(A, b, c_basis_diag)\n",
    "    c_tilde_h = c_bar.T @ (torch.eye(N) - A_bar.matrix_power(L))\n",
    "    c_tilde = c_tilde_h.H\n",
    "\n",
    "    # CNN form.\n",
    "    K = kernel_dplr(Lambda, b, c_tilde, p, L)\n",
    "\n",
    "    # RNN form.\n",
    "    Ab, Bb = discrete_dplr(Lambda, p, b, c, L)\n",
    "    K2 = k_conv(A_bar, b_bar, c_bar, L=L)\n",
    "    assert np.allclose(K, K2, atol=1e-5, rtol=1e-5)\n",
    "\n",
    "    # Apply CNN\n",
    "    u = torch.arange(L).type(torch.complex64)\n",
    "    y1 = causal_convolution(u, K)\n",
    "\n",
    "    # Apply RNN\n",
    "    _, y2 = scan_ssm(\n",
    "        Ab, Bb, c_bar.T, u[:, np.newaxis], torch.zeros((N,)).type(torch.complex64)\n",
    "    )\n",
    "    assert np.allclose(y1, y2.reshape(-1).real, atol=1e-4, rtol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_conversion()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-s4",
   "language": "python",
   "name": "env-s4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "a263f42c39b2fd75b37cb89946a27f6140cd004b337ff228565a862a637fff96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
