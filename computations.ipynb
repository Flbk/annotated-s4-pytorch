{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\RR}{\\mathbb{R}}\n",
    "\\newcommand{\\ZZ}{\\mathbb{Z}}\n",
    "\\newcommand{\\CC}{\\mathbb{C}}\n",
    "\\newcommand{\\EE}{\\mathbb{E}}\n",
    "\\newcommand{\\Zz}{\\mathcal{Z}}\n",
    "\\newcommand{\\Ww}{\\mathcal{W}}\n",
    "\\newcommand{\\Vv}{\\mathcal{V}}\n",
    "\\newcommand{\\Nn}{\\mathcal{N}}\n",
    "\\newcommand{\\NN}{\\mathcal{N}}\n",
    "\\newcommand{\\Hh}{\\mathcal{H}}\n",
    "\\newcommand{\\Bb}{\\mathcal{B}}\n",
    "\\newcommand{\\Ee}{\\mathcal{E}}\n",
    "\\newcommand{\\Cc}{\\mathcal{C}}\n",
    "\\newcommand{\\Gg}{\\mathcal{G}}\n",
    "\\newcommand{\\Ss}{\\mathcal{S}}\n",
    "\\newcommand{\\Pp}{\\mathcal{P}}\n",
    "\\newcommand{\\Ff}{\\mathcal{F}}\n",
    "\\newcommand{\\Xx}{\\mathcal{X}}\n",
    "\\newcommand{\\Mm}{\\mathcal{M}}\n",
    "\\newcommand{\\Ii}{\\mathcal{I}}\n",
    "\\newcommand{\\Dd}{\\mathcal{D}}\n",
    "\\newcommand{\\Ll}{\\mathcal{L}}\n",
    "\\newcommand{\\Tt}{\\mathcal{T}}\n",
    "\\newcommand{\\al}{\\alpha}\n",
    "\\newcommand{\\la}{\\lambda}\n",
    "\\newcommand{\\ga}{\\gamma}\n",
    "\\newcommand{\\Ga}{\\Gamma}\n",
    "\\newcommand{\\La}{\\Lambda}\n",
    "\\newcommand{\\si}{\\sigma}\n",
    "\\newcommand{\\Si}{\\Sigma}\n",
    "\\newcommand{\\be}{\\beta}\n",
    "\\newcommand{\\de}{\\delta}\n",
    "\\newcommand{\\De}{\\Delta}\n",
    "\\renewcommand{\\phi}{\\varphi}\n",
    "\\renewcommand{\\th}{\\theta}\n",
    "\\newcommand{\\om}{\\omega}\n",
    "\\newcommand{\\Om}{\\Omega}\n",
    "\\newcommand{\\eps}{\\varepsilon}\n",
    "\\newcommand{\\bo}[1]{\\boldsymbol{\\mathbf{#1}}}\n",
    "\\newcommand{\\bu}{\\bo{u}}\n",
    "\\newcommand{\\bv}{\\bo{v}}\n",
    "\\newcommand{\\bV}{\\bo{V}}\n",
    "\\newcommand{\\bC}{\\bo{C}}\n",
    "\\newcommand{\\bp}{\\bo{p}}\n",
    "\\newcommand{\\bq}{\\bo{q}}\n",
    "\\newcommand{\\bX}{\\bo{X}}\n",
    "\\newcommand{\\bc}{\\bo{c}}\n",
    "\\newcommand{\\bb}{\\bo{b}}\n",
    "\\newcommand{\\bh}{\\bo{h}}\n",
    "\\newcommand{\\by}{\\bo{y}}\n",
    "\\newcommand{\\lc}{\\bo{L}(\\bC)}\n",
    "\\newcommand{\\lcb}[1]{\\bo{L}(\\bo{#1})}\n",
    "\\newcommand{\\ba}{\\bo{a}}\n",
    "\\newcommand{\\bbv}{\\bo{b}}\n",
    "\\newcommand{\\tD}{\\bo{\\widetilde{D}}}\n",
    "\\newcommand{\\tLa}{\\bo{\\widetilde{\\La}}}\n",
    "\\newcommand{\\tCbe}{\\bo{\\widetilde{C}^{\\be}}}\n",
    "\\newcommand{\\bbe}{\\bo{\\beta}}\n",
    "\\newcommand{\\Cbe}{\\bC^{\\bbe}}\n",
    "\\newcommand{\\bhat}{\\bo{\\hat{\\be}}}\n",
    "\\newcommand{\\pibe}{\\bpi^{\\bbe}}\n",
    "\\newcommand{\\bD}{\\bo{D}}\n",
    "\\newcommand{\\bZ}{\\bo{Z}}\n",
    "\\newcommand{\\bF}{\\bo{F}}\n",
    "\\newcommand{\\bA}{\\bo{A}}\n",
    "\\newcommand{\\bB}{\\bo{B}}\n",
    "\\newcommand{\\bK}{\\bo{K}}\n",
    "\\newcommand{\\bI}{\\bo{I}}\n",
    "\\newcommand{\\bS}{\\bo{S}}\n",
    "\\newcommand{\\bLa}{\\bo{\\La}}\n",
    "\\newcommand{\\ctilde}{\\bo{\\tilde{c}}}\n",
    "\\newcommand{\\ptilde}{\\bo{\\tilde{p}}}\n",
    "\\newcommand{\\bhatK}{\\bo{\\hat{K}}}\n",
    "\\newcommand{\\bR}{\\bo{R}}\n",
    "\\newcommand{\\bAb}{\\bo{\\bar{A}}}\n",
    "\\newcommand{\\bbb}{\\bo{\\bar{b}}}\n",
    "\\newcommand{\\ut}{u_{<t}}\n",
    "\\newcommand{\\norm}[1]{\\|#1\\|}\n",
    "\\newcommand{\\clint}[1]{\\left[ #1 \\right]}\n",
    "\\newcommand{\\diff}{\\mathop{}\\!\\mathrm{d}}\n",
    "\\newcommand{\\dotp}[1]{\\left\\langle #1 \\right\\rangle}\n",
    "\\newcommand{\\bx}{\\bo{x}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S4 in Pytorch.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook aims at explaining the S4 layer described in [S4](https://arxiv.org/abs/2111.00396), with more details on practical use cases, as well as a simple Pytorch implementation.\n",
    "Some parts of this code are directly coming from the excellent guide [Annotated S4](https://srush.github.io/annotated-s4/).\n",
    "\n",
    "The goal of the notebook is to be as concise as possible while providing enough details for a full comprehension of a practical implementation of S4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelisation\n",
    "\n",
    "### Classical approaches\n",
    "\n",
    "Deep NLP has made huge progress since the arrival of the sequence-to-sequence models. A sequence-to-sequence model is a model that maps a sequence $u_0, \\dots, u_{L-1}$ to another sequence $y_0, \\dots, y_{L-1}$.\n",
    "\n",
    "The main approaches in NLP were first RNN, that mimics Hidden Markov Process. In simple terms, a RNN models a situation recursively:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\begin{cases}\n",
    "        h_{k+1} &=& g(u_{k+1}, h_k),\\\\\n",
    "        y_{k+1} &=& f(h_{k+1}).\n",
    "    \\end{cases}\n",
    "\\end{equation}\n",
    "where $h_k$ represents a hidden state. Here each output $y_k$ is built recursively on the precedent value $h_{k-1}$. The main drawbacks of such models is that it is extremely difficult control how the information of previous steps flows up to the current step. It has even been derived that statistically such networks doesn't have long-memory (i.e the output at step $k$ is unlikely to have retained information of $u_{k-l}$if $l$ is large enough).\n",
    "\n",
    "The other and currently SOTA architecture is the transformer.\n",
    "\n",
    "Transformers are extremelly powerful because the output sequence depends directly on *all* the previous steps:\n",
    "\n",
    "\\begin{equation}\n",
    "    y_{k+1} = \\sum_{i=0}^{k} f(u_i, u_{k+1}).\n",
    "\\end{equation}\n",
    "\n",
    "Therefore they do have long-memory. But here the problem comes form the memory consumption of such operation. To process a full sequence the memory complexity is $\\mathcal{O}(L^2)$.\n",
    "\n",
    "### State-space approach\n",
    "\n",
    "To overcome these problems, S4 introduces the formalism of state-space models. Here $u_k \\in \\RR$ is a scalar input.\n",
    "\n",
    "\\begin{equation}\\label{eq:state-space}\n",
    "    \\begin{cases}\n",
    "        x_{k+1} = \\bA x_k + \\bb u_k,\\\\\n",
    "        y_{k+1} = \\bc^T x_{k+1}.\n",
    "    \\end{cases}\n",
    "\\end{equation}\n",
    "where $x_k \\in \\RR^N$ is a vector and obviously $\\bc \\in \\RR^N$. For multidimensionnal inputs, we simply apply these steps (with the same parameters) independently to all coordinates.\n",
    "\n",
    "Let's write a first implementation of such a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseSSM:\n",
    "    def __init__(self, A, b, c):\n",
    "        self.A = A\n",
    "        self.b = b\n",
    "        self.c = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSSM(BaseSSM):\n",
    "    def __call__(self, u, L):\n",
    "\n",
    "        y = torch.zeros(L)\n",
    "        x_k = 0\n",
    "        for i in range(L):\n",
    "            x_k += b * u[i]\n",
    "            y_k = self.c.T @ x_k\n",
    "            y[i] = y_k\n",
    "            x_k = self.A @ x_k\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "L = 5\n",
    "\n",
    "A = torch.randn(N, N)\n",
    "b = torch.rand(N, 1)\n",
    "c = torch.rand(N, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_ssm = SimpleSSM(A, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f839d6f6280>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_interval = torch.arange(L)\n",
    "u = torch.sin(2 * torch.pi * torch.arange(L) / L)\n",
    "plt.plot(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f839b58f1c0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = simple_ssm(u, L)\n",
    "plt.plot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State-space computations\n",
    "\n",
    "Now let's take a step back and remember that our goal is to train a model, whose parameters will include $\\bA, \\bb, \\bc$.\n",
    "\n",
    "However if the formulation of \\eqref{eq:state-space} seems simple, it is in fact quite complicated for training, due do its recursive definition (same problems faced during training of RNN actually).\n",
    "\n",
    "A big advantage of transformers is the possibility to process in parallel the whole sequence, that greatly improves the training speed and the backpropagation of the gradient is more easy than with recursive architectures.\n",
    "\n",
    "Hence a legitimate question is: do we have the same property with S4? And the answer is yes!\n",
    "\n",
    "To explain it, we are now going to focus exclusively on training, i.e when the full input and output are already available. Later, we will explain how we can generate outputs in an autoregressive manner.\n",
    "\n",
    "## Training - Convolution view\n",
    "\n",
    "One can notice that if we unrol \\eqref{eq:state-space}, $y \\in \\RR^L$ can be directly expressed as a convolution between the input $u \\in \\RR^L$ and a filter $\\bK \\in \\RR^L$:\n",
    "\n",
    "\\begin{align}\n",
    "    y_0 &= \\bc^T\\bb u_0,\\\\\n",
    "    y_1 &= \\bc^T\\bA\\bb u_0 + \\bc^T\\bb u_1,\\\\\n",
    "    y_2 &= \\bc^T \\bA^2 \\bb u_0 + \\bc^T\\bA\\bb u_1 + \\bc^T\\bb u_2,\\\\\n",
    "    \\vdots\\\\\n",
    "    y_k &= \\sum_{i=0}^k \\bc^T\\bA^i\\bb u_{k - i}.\n",
    "\\end{align}\n",
    "\n",
    "We have therefore: $y = \\bK * u$, with $\\bK = \\left(\\bc^T \\bb, \\bc^T\\bA\\bb, \\dots, \\bc^T\\bA^{L-1}\\bb\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good news: a convolution can be computed in $\\mathcal{O}(L \\log L)$ once the filter $\\bK$ is known, using Discrete Fourier Transform (with padding to avoid circular convolution).\n",
    "\n",
    "Compared to the quadratic complexity of transformers, we have a huge gain in term of memory usage.\n",
    "\n",
    "Let's write a first function to see what it gives.\n",
    "\n",
    "*Remark:* In the following code you will see some functions characteristic of hermitian product in a complex vector space. This is because later we will work in $\\CC^N$ instead of $\\RR^N$. For now you can ignore it and just think of `c.H` as `c.T` for the adjoint operator and ignore `c.conj()` (that we use sometimes to compute the adjoint operator indirectly).\n",
    "\n",
    "But sometimes some operations are also needed because of floating points error (like taking the real part after inverse Fourier Transform). When there is ambiguity we will write some comments in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_simple(A, b, c, L):\n",
    "    K = [(c.H @ A.matrix_power(l) @ b).item() for l in range(L)]\n",
    "    \n",
    "    # We take the real part because later we will use complex numbers.\n",
    "    # But because K depends only on real values matrices, it should be real (up to floating point error on the imaginary part).\n",
    "    return torch.tensor(K).real\n",
    "\n",
    "def causal_convolution(u, K):\n",
    "    convolution_shape = u.shape[0] + K.shape[0]\n",
    "    \n",
    "    # Specifying the paramter 'n' will automatically pad our vectors to the right dimension.\n",
    "    u_fft = torch.fft.fft(u, n=convolution_shape)\n",
    "    K_fft = torch.fft.fft(K, n=convolution_shape)\n",
    "    out = u_fft * K_fft\n",
    "    return torch.fft.ifft(out).real[: u.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConvSSM(BaseSSM):\n",
    "    \n",
    "    def __call__(self, u, L):\n",
    "    \n",
    "        K = kernel_simple(self.A, self.b, self.c, L)\n",
    "        y = causal_convolution(u, K)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_conv_ssm = SimpleConvSSM(A, b, c)\n",
    "y_conv = simple_conv_ssm(u, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(y, y_conv, atol=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the main bottleneck of this computation is how we obtain the convolution kernel. We exponentiate a matrix $L$ times, compute a lot of matrix products etc, which is highly non efficient and non stable from a numerical point of view.\n",
    "\n",
    "To make this more efficient, we can find more sophisticated algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Namely, instead of computing directly $\\bK$, we are going to compute its DFT, $\\bhatK$ and then simply apply a inverse Fourier Transform (IDFT). Let $\\om_k = \\exp\\left(-{\\dfrac{2i \\pi k}{N}}\\right)$.\n",
    "\n",
    "\\begin{align}\\label{eq:K-spectrum}\n",
    "    \\bhatK_k &= \\sum_{i=0}^{L-1} \\bK_i \\omega_k^i,\\\\\n",
    "    &= \\sum \\bc^T A^i b \\omega_k^i,\\\\\n",
    "    &= \\bc^T \\left(\\sum \\bA^i \\omega_k^i \\right) \\bb,\\\\\n",
    "    &= \\bc^T (\\bI - \\bA^L)(\\bI - \\bA\\omega_k)^{-1} \\bb.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this does not really reduce the complexity, because now we have to compute an inverse $L$ times (for each $\\om_k$), giving a complexity of $\\mathcal{O}(LN^3)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretization and special decomposition\n",
    "\n",
    "TLDR: Instead of directly dealing with the matrices $\\bA$ and $\\bb$ we are going to use slightly modified versions $\\bAb, \\bbb$. This is because of a discretization process.\n",
    "\n",
    "\\begin{equation}\n",
    "    \\begin{cases}\n",
    "        \\bAb &= \\left(\\bI - \\dfrac{1}{2}\\bA \\right)^{-1}\\left(\\bI + \\dfrac{1}{2}\\bA\\right),\\\\\n",
    "        \\bbb &= \\left(\\bI - \\dfrac{1}{2}\\bA \\right)^{-1}\\bb.\n",
    "    \\end{cases}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize(A, b, step=1):\n",
    "    I = torch.eye(A.shape[0])\n",
    "    left_term = torch.linalg.inv(I - (step / 2.0) * A)\n",
    "    A_bar = left_term @ (I + (step / 2.0) * A)\n",
    "    b_bar = (left_term * step) @ b\n",
    "    return A_bar, b_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also assume that $\\bA$ is similar to a matrix of the form $\\bLa - \\bp^* \\bp$, where we now considerate matrix and vectors with coefficients in $\\CC$.\n",
    "Where $\\bLa \\in \\CC^{N \\times N}$ is diagonal and $\\bp \\in \\CC^{N \\times 1}$.\n",
    "$.^*$ designated the hermitian adjoint (= transpose + conjugate) of a matrix (a vector is viewed as a matrix of $\\CC^{N \\times 1}$).\n",
    "This decomposition is called Diagonal Plus Low Rank (DPLR).\n",
    "\n",
    "*Remark:* In the original article the derivations are made with $\\bA \\sim \\bLa + \\bq^* \\bp$. But in practice in S4 we use $-\\bp = \\bq$ which is valid and works better for numerical reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, the matrix $A$ we are using can be decomposed in the following form:\n",
    "\\begin{equation}\n",
    "    \\bA = - \\dfrac{1}{2}\\bI - \\bS - \\bp^*\\bp,\n",
    "\\end{equation}\n",
    "where $\\bS$ is a skew-hermitian matrix ($\\bS = - \\bS^*$), and $\\bp \\in \\RR^{N}$ is a vector of dimension 1.\n",
    "\n",
    "And in the adapted basis, the inverse of a DLPR matrix is much more easy to compute, thanks to the Woodburry inversion formula:\n",
    "\n",
    "\\begin{equation}\n",
    "    (\\bLa - \\bp^* \\bq)^{-1} = \\bLa^{-1} + \\bLa^{-1}\\bp \\left(1 - \\bq^*\\bLa^{-1} \\bp\\right)^{-1}\\bq^* \\bLa^{-1}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we apply this result to the expression of $\\bhatK$ \\eqref{eq:K-spectrum} using $\\bAb$ and $\\bbb$, with some more algebraic operations, we obtain a quite simple formula for its expression:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\bhatK_k = \\dfrac{2}{1 + \\om_k}\\left[\\ctilde^* \\bR_k \\bb - \\ctilde^* \\bR_k \\bp (1 + \\bp^*\\bR_k \\bp)^{-1}\\bp^*\\bR_k \\bb\\right].\n",
    "\\end{equation}\n",
    "\n",
    "with $\\bR_k = \\left(2\\dfrac{1 - \\om_k}{1 + \\om_k} - \\bLa \\right)^{-1}$ and $\\ctilde^* = \\bc^* (\\bI - \\bAb^L)$.\n",
    "\n",
    "And here, in fact all the matrix multiplications can be evaluated very efficiently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\\label{eq:cauchy-K}\n",
    "   \\ctilde^T \\bR_k \\bb &= \\sum_{i=1}^{N} \\dfrac{\\ctilde_i \\bb_i}{\\om_k - \\bLa_i},\n",
    "\\end{align}\n",
    "\n",
    "and because we want to compute it for all $\\om_k$, the complexity reduces to $\\mathcal{O}(NL)$.\n",
    "In fact, we can be even more efficient, but we need to rely on algorithms that are not yet implemented on Pytorch.\n",
    "But notice that this complexity is not a bottleneck when the biggest memory cost comes from the size of the sequence.\n",
    "\n",
    "Computing operation \\eqref{eq:cauchy-K} for all $k$ is actually a Cauchy product, a well studied problem in the litterature. We are going to implement it in a naive way, but again it won't be the main bottleneck of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_c_tilde(A, c, L):\n",
    "    return (torch.eye(A.shape[0]) - A.matrix_power(L)).H @ c\n",
    "\n",
    "def cauchy(p, q, Lambd, omega_L):\n",
    "    omega_L = 2. * ((1. - omega_L) / (1 + omega_L))\n",
    "    dot_product = p.conj() * q\n",
    "\n",
    "    Lambd = Lambd[:, None]\n",
    "    omega_L = omega_L[None, :]\n",
    "    cauchy_product = dot_product / (omega_L - Lambd)\n",
    "    return cauchy_product.sum(axis=-2)\n",
    "\n",
    "def kernel_dplr(Lambd, p, b, c_tilde, L):\n",
    "    omega_L = torch.exp((-2j * torch.pi) * torch.arange(L) / L)\n",
    "    term_1 = cauchy(c_tilde, b, Lambd, omega_L)\n",
    "    term_2 = cauchy(c_tilde, p, Lambd, omega_L)\n",
    "    term_3 = 1. / (1. + cauchy(p, p, Lambd, omega_L))\n",
    "    term_4 = cauchy(p, b, Lambd, omega_L)\n",
    "    \n",
    "    K_fft = (2. / (1. + omega_L)) * (term_1 - term_2 * term_3 * term_4) \n",
    "    return torch.fft.ifft(K_fft, L).real\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lambd = -torch.rand(N) # use negative real parts to get more stability\n",
    "p = torch.randn(N, 1)\n",
    "b = torch.randn(N, 1)\n",
    "c = torch.randn(N, 1)\n",
    "\n",
    "A = torch.diag(Lambd) - p @ p.H\n",
    "\n",
    "A_bar, b_bar = discretize(A, b)\n",
    "\n",
    "\n",
    "c_tilde = compute_c_tilde(A_bar, c, L)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_dplr = kernel_dplr(Lambd, p, b, c_tilde, L)\n",
    "K_simple = kernel_simple(A_bar, b_bar, c, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(K_simple, K_dplr, atol=1e-4, rtol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientConvSSM(BaseSSM):\n",
    "    def __init__(self, Lambd, p, b, c):\n",
    "        self.Lambd = Lambd\n",
    "        self.p = p\n",
    "        self.b = b\n",
    "        self.c = c\n",
    "        \n",
    "    def __call__(self, u, L):\n",
    "        A = torch.diag(self.Lambd) - p @ p.H\n",
    "        A_bar, _ = discretize(A, self.b)\n",
    "        c_tilde = compute_c_tilde(A_bar, c, L)\n",
    "        K = kernel_dplr(self.Lambd, p, b, c_tilde, L)\n",
    "        y = causal_convolution(u, K)\n",
    "        return y\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficient_conv_ssm = EfficientConvSSM(Lambd, p, b, c)\n",
    "y_efficient_conv = efficient_conv_ssm(u, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_conv_ssm = SimpleConvSSM(A_bar, b_bar, c)\n",
    "y_simple_conv = simple_conv_ssm(u, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(y_efficient_conv, y_simple_conv, atol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multidimensionnal data\n",
    "\n",
    "Until now we have supposed that our sequence $\\bu$ is 1D. As said earlier, a direct way to generalize everything is to apply all this processing to all dimensions independently.\n",
    "\n",
    "And in addition we are also going to consider a batch dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseMultiSSM:\n",
    "    def __init__(self, A, b, c):\n",
    "        self.A = A # (H, N, N)\n",
    "        self.b = b # (H, N, 1)\n",
    "        self.c = c # (H, N, 1)\n",
    "        \n",
    "class SimpleMultiConvSSM(BaseMultiSSM):\n",
    "    def __call__(self, u, L):\n",
    "        y = torch.zeros_like(u)\n",
    "        for batch_dim in range(u.shape[0]):\n",
    "            for hidden_dim in range(u.shape[2]):\n",
    "                A_hidden = self.A[hidden_dim]\n",
    "                b_hidden = self.b[hidden_dim]\n",
    "                c_hidden = self.c[hidden_dim]\n",
    "                K = kernel_simple(A, b, c, L)\n",
    "                y[batch_dim, :, hidden_dim] = causal_convolution(u[batch_dim, :, hidden_dim], K)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first vectorize the discretization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_multi(A, b, step=1):\n",
    "    I = torch.eye(A.shape[1])\n",
    "    left_term = torch.linalg.inv(I[None, :, :] - (step / 2.0) * A)\n",
    "    A_bar = left_term @ (I + (step / 2.0) * A)\n",
    "    b_bar = (left_term * step) @ b\n",
    "    return A_bar, b_bar\n",
    "\n",
    "def discretize_multi_simple(A, b, step=1):\n",
    "    A_bar = torch.zeros_like(A)\n",
    "    b_bar = torch.zeros_like(b)\n",
    "    for h in range(A.shape[0]):\n",
    "        A_bar[h], b_bar[h] = discretize(A[h], b[h], step=step)\n",
    "    return A_bar, b_bar\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 3\n",
    "A = torch.randn(H, N, N)\n",
    "b = torch.randn(H, N, 1)\n",
    "c = torch.randn(H, N, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_bar, b_bar = discretize_multi(A, b)\n",
    "A_bar_simple, b_bar_simple = discretize_multi_simple(A, b)\n",
    "\n",
    "assert torch.allclose(A_bar_simple, A_bar)\n",
    "assert torch.allclose(b_bar, b_bar_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the kernel generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_c_tilde_multi(A, c, L):\n",
    "    return (torch.eye(A.shape[1])[None, :, :] - A.matrix_power(L)).mH @ c\n",
    "\n",
    "def cauchy_multi(p, q, Lambd, omega_L):\n",
    "    omega_L = 2. * ((1. - omega_L) / (1 + omega_L))\n",
    "    dot_product = p * q\n",
    "\n",
    "    Lambd = Lambd[:, :, None]\n",
    "    omega_L = omega_L[None, None, :]\n",
    "    cauchy_product = dot_product / (omega_L - Lambd)\n",
    "    return cauchy_product.sum(axis=-2)\n",
    "\n",
    "def kernel_dplr_multi(Lambd, p, b, c_tilde, L):\n",
    "    omega_L = torch.exp((-2j * torch.pi) * torch.arange(L) / L)\n",
    "    term_1 = cauchy_multi(b, c_tilde, Lambd, omega_L)\n",
    "    term_2 = cauchy_multi(c_tilde, p, Lambd, omega_L)\n",
    "    term_3 = 1. / (1. + cauchy_multi(p.conj(), p, Lambd, omega_L))\n",
    "    term_4 = cauchy_multi(p.conj(), b, Lambd, omega_L)\n",
    "    \n",
    "    K_fft = (2. / (1. + omega_L[None, :])) * (term_1 - term_2 * term_3 * term_4) \n",
    "    return torch.fft.ifft(K_fft, L).real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a utility function to help us \"vectorize\" our unidimensionnal functions for testing (it just does a for loop but it will help us avoid repeating code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_multi(func):\n",
    "    \"\"\"Makes a function handle multi dimensionnal inputs.\n",
    "    This is not optimized and should only be used for testing purposes.\"\"\"\n",
    "    def multi_inputs(*args):\n",
    "        out = []\n",
    "        hidden_dim = args[0].shape[0]\n",
    "\n",
    "        args = list(args)\n",
    "        for i in range(len(args)):\n",
    "            if (not isinstance(args[i], torch.Tensor)) or (args[i].shape[0] != hidden_dim):\n",
    "                args[i] = [args[i] for _ in range(hidden_dim)]\n",
    "\n",
    "        for h in range(hidden_dim):\n",
    "            out.append(func(*[input_tensor[h] for input_tensor in args]).tolist())\n",
    "        return torch.tensor(out)\n",
    "    return multi_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(A, torch.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_tilde = compute_c_tilde_multi(A, c, L)\n",
    "\n",
    "compute_c_tilde_multi_simple = make_multi(compute_c_tilde)\n",
    "c_tilde_simple = compute_c_tilde_multi_simple(A, c, L)\n",
    "\n",
    "assert torch.allclose(c_tilde, c_tilde_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.randn(H, N, 1)\n",
    "q = torch.randn(H, N, 1)\n",
    "Lambd = torch.randn(H, N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega_L = torch.exp((-2j * torch.pi) * torch.arange(L) / L)\n",
    "\n",
    "prod = cauchy_multi(p, q, Lambd, omega_L)\n",
    "\n",
    "cauchy_multi_simple = make_multi(cauchy)\n",
    "prod_simple = cauchy_multi_simple(p, q, Lambd, omega_L)\n",
    "\n",
    "assert torch.allclose(prod_simple, prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.randn(H, N, 1)\n",
    "b = torch.randn(H, N, 1)\n",
    "c = torch.randn(H, N, 1)\n",
    "Lambd = torch.randn(H, N)\n",
    "\n",
    "K = kernel_dplr_multi(Lambd, p, b, c, L)\n",
    "\n",
    "kernel_dplr_multi_simple = make_multi(kernel_dplr)\n",
    "\n",
    "K_simple = kernel_dplr_multi_simple(Lambd, p, b, c, L)\n",
    "\n",
    "assert torch.allclose(K, K_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def causal_convolution_multi(u, K):\n",
    "    fft_shape = u.shape[2] + K.shape[1]\n",
    "    u_fft = torch.fft.fft(u, n=fft_shape, axis=-1)\n",
    "    K_fft = torch.fft.fft(K, n=fft_shape, axis=-1)\n",
    "    out = u_fft * K_fft\n",
    "    return torch.fft.ifft(out, axis=-1)[:, :, :u.shape[2]].real\n",
    "\n",
    "\n",
    "def causal_convolution_multi_simple(u, K):\n",
    "    out = torch.zeros_like(u)\n",
    "    for i in range(u.shape[0]):\n",
    "        for j in range(u.shape[1]):\n",
    "            out[i, j, :] = causal_convolution(u[i, j, :], K[j])\n",
    "    return out\n",
    "\n",
    "\n",
    "def test_convolution_multi(batch_size=8, seq_length=10, hidden_size=5):\n",
    "    u = torch.randn(batch_size, hidden_size, seq_length)\n",
    "    K = torch.randn(hidden_size, seq_length)    \n",
    "    \n",
    "    y_simple = causal_convolution_multi_simple(u, K)\n",
    "    y = causal_convolution_multi(u, K)\n",
    "    assert torch.allclose(y, y_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_convolution_multi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to implement everything in a `nn.Module` class.\n",
    "We have indeed a desribed a valid model whose parameters are $\\bLa, \\bb, \\bp, \\bc$.\n",
    "\n",
    "There is however a last detail on which we should spend some time. Indeed, we are going to initialize $\\bLa, \\bb, \\bp$ with very special values. This is also this initializatin which is going to explain why this S4 model works so well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HiPPO matrix\n",
    "\n",
    "First a bit of context. In the previous section we have introduced a discretized version as well as DPLR decomposition for $\\bA$. But the main contribution of the article is to provide a value of $\\bA$ that will efficiently keep in memory the information on the whole sequence.\n",
    "\n",
    "To do that, let's go back in the continuous domain and consider $u(t)$, $u \\colon \\RR^+ \\to \\RR$ a scalar continuous function. Because we are in the end interesting in autoregressive generation, let's introduce $\\ut = u \\mathbf{1}_{\\clint{0, t}}$. And what the authors propose is to approximate this function on a polynomial basis.\n",
    "\n",
    "For time $t$ we choose an orthogonal polynomial basis $(P_n^t)_{0\\leq n \\leq N-1}\\in \\RR_N[X]$ for the scalar product $\\dotp{u, v} = \\displaystyle\\int_0^t u v \\diff \\lambda$ (typically we orthogonalize the canonical basis).\n",
    "\n",
    "$\\forall n \\in [0..N-1]$ the coefficients $x_n(t)$ of the projection are simply given by:\n",
    "\n",
    "\\begin{equation}\\label{eq:coefs}\n",
    "    x_n(t) = \\displaystyle\\int_0^t u(s) P^t_n(s) \\diff s.\n",
    "\\end{equation}\n",
    "\n",
    "When we differentiate \\eqref{eq:coefs} (see the original paper for the details), we find something that again depends on the $x_1, \\dots, x_N$ and $\\ut$, hence we have an ODE of the form:\n",
    "\n",
    "\\begin{equation}\\label{eq:ode}\n",
    "    \\dfrac{d \\bx}{dt}(t) = \\bA \\bx(s) + u(s)\\bb(s),\n",
    "\\end{equation}\n",
    "with \\textbf{tractable} $\\bA \\in \\RR^{N \\times N}$ and $\\bb \\in \\RR^N$.\n",
    "\n",
    "At each time $t$, $\\bx(t) \\in \\RR^N$ represents the whole function $\\ut$. Hence, the memory property.\n",
    "\n",
    "And it happens that for the Legend polynomial basis, the matrices $\\bA$ and $\\bb$ have a closed form expression:\n",
    "\n",
    "\\begin{array}{rrrl}\n",
    "    \\forall i, j \\in [0..N-1], & \\, \\bA_{ij} & = & -\n",
    "    \\begin{cases}\n",
    "        (2i + 1)^{1/2}(2j + 1)^{1/2} &\\quad \\text{if} \\, i > j,\\\\\n",
    "        i + 1 &\\quad \\text{if} \\, i = j,\\\\\n",
    "        0 &\\quad \\text{if} \\, i < j,\n",
    "    \\end{cases}\\\\\n",
    "    \\forall i \\in [0..N-1], & \\, \\bb_i & = & (2i + 1)^{1/2}.\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hippo_matrices(N):\n",
    "    u = torch.arange(N)\n",
    "    b = torch.sqrt(2 * u[:, None] + 1)\n",
    "    A = b @ b.T\n",
    "    A = torch.tril(A, 0)\n",
    "    A = - (A - torch.diag(u))\n",
    "\n",
    "    return A, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000, -0.0000, -0.0000, -0.0000],\n",
       "        [-1.7321, -2.0000, -0.0000, -0.0000],\n",
       "        [-2.2361, -3.8730, -3.0000, -0.0000],\n",
       "        [-2.6458, -4.5826, -5.9161, -4.0000]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, b = hippo_matrices(4)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we notice immediately that if $\\ptilde = \\dfrac{1}{\\sqrt{2}}\\bb$, then:\n",
    "\n",
    "\\begin{align}\n",
    "    \\bA + \\ptilde \\ptilde^t &= -\\begin{cases}\n",
    "        \\dfrac{1}{2}(2i + 1)^{1/2}(2j + 1)^{1/2} &\\quad \\text{if} \\, i > j,\\\\\n",
    "        \\dfrac{1}{2} &\\quad \\text{if} \\, i = j,\\\\\n",
    "        -\\dfrac{1}{2}(2i + 1)^{1/2}(2j + 1)^{1/2} &\\quad \\text{if} \\, i < j,\n",
    "    \\end{cases}\\\\\n",
    "    &= -\\dfrac{1}{2}\\bI - \\bS\n",
    "\\end{align}\n",
    "where $\\bS$ is a skew-symmetric matrix:\n",
    "\n",
    "\\begin{equation}\n",
    "\\bS =\n",
    "\\begin{cases}\n",
    "        \\dfrac{1}{2}(2i + 1)^{1/2}(2j + 1)^{1/2} &\\quad \\text{if} \\, i > j,\\\\\n",
    "        0 &\\quad \\text{if} \\, i = j,\\\\\n",
    "        -\\dfrac{1}{2}(2i + 1)^{1/2}(2j + 1)^{1/2} &\\quad \\text{if} \\, i < j,\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "And a skew-symmetric matrix can be diagonalized (in $\\CC$), hence it means that $\\bA$ is similar to a DPLR matrix!\n",
    "\n",
    "\\begin{equation}\n",
    "\\exists \\bV \\in \\mathcal{O}_N(\\CC),\\, \\bA = \\bV \\left( \\bLa - \\bp \\bp^* \\right) \\bV^*,\n",
    "\\end{equation}\n",
    "\n",
    "with $\\bV$ the matrix representing the (complex) eigenvectors of $\\bS$, $\\mathcal{O}_N(\\CC)$ the set of orthogonal matrices of size $N$ in $\\CC$, and $\\bp = \\bV^* \\ptilde$.\n",
    "Note that we should not forget to also change the basis of $\\bb$ when we want to use the special form $\\bA = \\bLa - \\bp \\bp^*$.\n",
    "\n",
    "We now have everything to initialize our parameters:\n",
    "\n",
    "- Create $\\bA, \\bp$ and $\\bb$ with their closed form expressions.\n",
    "- Instead of optimizing $\\bc$ we are going to optimize $\\ctilde$ which is in fact the only part where $\\bc$ is used. It will help reducing the number of operations and especially avoid exponentiating $\\bA$ (this is however a bit incorrect because we are losing the property that the output is real, but we can hope the neural network will learn a 'good' $\\ctilde$ which in the end has this property).\n",
    "- Initialize $\\ctilde$ at random.\n",
    "- Extract $\\bS$ from $\\bA$ and compute its eigenbasis.\n",
    "- Change the basis of $\\bp, \\bb$.\n",
    "- Initialize $\\bD$ at random that we are going to use as a \"skip connection\".\n",
    "\n",
    "From now all our vectors are going to be complex.\n",
    "\n",
    "Let's write that in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hippo_matrices_dplr(N):\n",
    "    u = torch.arange(N)[:, None]\n",
    "    \n",
    "    p_tilde = torch.sqrt(u + 0.5)\n",
    "\n",
    "    # Construct S\n",
    "    S = torch.tril(p_tilde @ p_tilde.T)\n",
    "    S = - S + S.T\n",
    "\n",
    "    # A small trick to make a skew-hermitian matrix a hermitian one.\n",
    "    hermitian_S = S * -1j\n",
    "    \n",
    "    # Diagonalize S and extract V.\n",
    "    Lambda, V = torch.linalg.eigh(hermitian_S)\n",
    "\n",
    "\n",
    "    # Mutliplies back the eigenvalues by (1j)^-1 to retrieve the original eigenvalues of the skew-hermitian matrix.\n",
    "    # We have to add the real parts of the eigenvalues, coming for the 1/2*Id part of the decomposition. \n",
    "    Lambda = Lambda * 1j - 0.5\n",
    "    \n",
    "    b = torch.sqrt(2 * u + 1)\n",
    "    \n",
    "    # Change of basis for b and p.\n",
    "    b = V.H @ b.type(torch.complex64)\n",
    "    p = V.H @ p_tilde.type(torch.complex64)\n",
    "    \n",
    "    return V, Lambda, p, b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "V, Lambda, p, b = hippo_matrices_dplr(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if we did not make any mistakes in our change of basis by comparing $\\bA$ obtained from the direct formula and the one obtained through diagonalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, b = hippo_matrices(N)\n",
    "\n",
    "assert torch.allclose(V @ (torch.diag(Lambda) - p @ p.H) @ V.H, A.type(torch.complex64), atol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before getting to the full implementation, we are going to explain how we can perform autoregressive decoding.\n",
    "Indeed, when doing a convolution, we assume that the whole input in known. In autoregressive decoding it is not the cae anymore. We therefore have to get back to the basic definition of the state-space system.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent decoding\n",
    "The authors derived a computation of each step in $\\mathcal{O}(N)$ (instead of a naive $\\mathcal{O}(N^2))$, by leveraging the DPLR form of $\\bA$ with single unidimensional inputs, and $\\mathcal{O}(HN)$ with H-dimensional inputs and $N$ the polynomial space dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_dplr(Lambda, p, b, c, L, step=1.):\n",
    "    # Convert parameters to matrices\n",
    "    N = Lambda.shape[0]\n",
    "    A = torch.diag(Lambda) - p @ p.H\n",
    "    I = torch.eye(N)\n",
    "\n",
    "    # Forward Euler\n",
    "    A_0 = (2.0 / step) * I + A\n",
    "\n",
    "    # Backward Euler\n",
    "    D = torch.diag(1.0 / ((2.0 / step) - Lambda))\n",
    "    D_p = D @ p\n",
    "    \n",
    "    A_1 = D - (D_p * (1.0 / (1 + (p.H @ D_p))) * p.H @ D)\n",
    "\n",
    "    # A bar and B bar\n",
    "    A_bar = A_1 @ A_0\n",
    "    b_bar = 2 * A_1 @ b\n",
    "\n",
    "    return A_bar, b_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_ssm(A_bar, b_bar, c_bar, u, x_0):\n",
    "    def step(x_k_1, u_k):\n",
    "        x_k = A_bar @ x_k_1 + b_bar @ u_k\n",
    "        y_k = c_bar @ x_k\n",
    "        return x_k, y_k\n",
    "    recurrence = []\n",
    "    x_k = x_0\n",
    "    for i in range(u.shape[0]):\n",
    "        x_k, y_k = step(x_k, u[i])\n",
    "        recurrence.append(y_k)\n",
    "    return x_k, torch.tensor(recurrence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_conversion(N=8, L=16):\n",
    "    V, Lambda, p, b = hippo_matrices_dplr(N)\n",
    "    A = torch.diag(Lambda) - p @ p.H\n",
    "    c_base = torch.randn(N, 1)\n",
    "    c = V.H @ c_base.type(torch.complex64)\n",
    "    A_bar, b_bar = discretize(A, b)\n",
    "    c_tilde = compute_c_tilde(A_bar, c, L)\n",
    "\n",
    "    # CNN form.\n",
    "    K = kernel_dplr(Lambda, p, b, c_tilde, L)\n",
    "\n",
    "    # RNN form.\n",
    "    K_simple = kernel_simple(A_bar, b_bar, c, L=L)\n",
    "\n",
    "    assert np.allclose(K, K_simple, atol=1e-4)\n",
    "\n",
    "    # Apply CNN\n",
    "    u = torch.arange(L).type(torch.complex64)\n",
    "    y1 = causal_convolution(u, K)\n",
    "\n",
    "    # Apply RNN\n",
    "    _, y2 = scan_ssm(\n",
    "        A_bar, b_bar, c.H, u[:, None], torch.zeros((N,)).type(torch.complex64)\n",
    "    )\n",
    "    assert np.allclose(y1, y2.reshape(-1).real, atol=1e-4, rtol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_conversion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4075, 1.2344])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 4)\n",
    "torch.diag(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_dplr_multi(Lambda, p, b, c, L, step=1.):\n",
    "    # Convert parameters to matrices\n",
    "    N = Lambda.shape[1]\n",
    "    I = torch.eye(N)[None, :, :]\n",
    "    A = Lambd[:, :, None] * I - p @ p.mH\n",
    "    \n",
    "\n",
    "    # Forward Euler\n",
    "    A_0 = (2.0 / step) * I + A\n",
    "\n",
    "    # Backward Euler\n",
    "    D = (1.0 / ((2.0 / step) - Lambda)) * I\n",
    "    D_p = D @ p\n",
    "    \n",
    "    A_1 = D - (D_p * (1.0 / (1 + (p.mH @ D_p))) * p.mH @ D)\n",
    "\n",
    "    # A bar and b bar\n",
    "    A_bar = A_1 @ A_0\n",
    "    b_bar = 2 * A_1 @ b\n",
    "\n",
    "    return A_bar, b_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, got 1, 1x10,1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [48]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m A_bar, b_bar \u001b[38;5;241m=\u001b[39m discrete_dplr_multi(Lambda, p, b, c, L)\n\u001b[1;32m     11\u001b[0m discrete_dplr_multi_simple \u001b[38;5;241m=\u001b[39m make_multi(discrete_dplr)\n\u001b[0;32m---> 13\u001b[0m A_bar_simple, b_bar_simple \u001b[38;5;241m=\u001b[39m \u001b[43mdiscrete_dplr_multi_simple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLambda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36mmake_multi.<locals>.multi_inputs\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     11\u001b[0m         args[i] \u001b[38;5;241m=\u001b[39m [args[i] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(hidden_dim)]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(hidden_dim):\n\u001b[0;32m---> 14\u001b[0m     out\u001b[38;5;241m.\u001b[39mappend(\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mh\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(out)\n",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36mdiscrete_dplr\u001b[0;34m(Lambda, p, b, c, L, step)\u001b[0m\n\u001b[1;32m     11\u001b[0m D \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdiag(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m ((\u001b[38;5;241m2.0\u001b[39m \u001b[38;5;241m/\u001b[39m step) \u001b[38;5;241m-\u001b[39m Lambda))\n\u001b[1;32m     12\u001b[0m D_p \u001b[38;5;241m=\u001b[39m D \u001b[38;5;241m@\u001b[39m p\n\u001b[0;32m---> 14\u001b[0m A_1 \u001b[38;5;241m=\u001b[39m D \u001b[38;5;241m-\u001b[39m (D_p \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m (\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mH\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mD_p\u001b[49m))) \u001b[38;5;241m*\u001b[39m p\u001b[38;5;241m.\u001b[39mH \u001b[38;5;241m@\u001b[39m D)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# A bar and B bar\u001b[39;00m\n\u001b[1;32m     17\u001b[0m A_bar \u001b[38;5;241m=\u001b[39m A_1 \u001b[38;5;241m@\u001b[39m A_0\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, got 1, 1x10,1"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "L = 10\n",
    "H = 3\n",
    "Lambda = torch.randn(3, N, N)\n",
    "p = torch.randn(3, N, 1)\n",
    "b = torch.randn(3, N, 1)\n",
    "c = torch.randn(3, N, 1)\n",
    "\n",
    "A_bar, b_bar = discrete_dplr_multi(Lambda, p, b, c, L)\n",
    "\n",
    "discrete_dplr_multi_simple = make_multi(discrete_dplr)\n",
    "\n",
    "A_bar_simple, b_bar_simple = discrete_dplr_multi_simple(Lambda, p, b, c, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-s4",
   "language": "python",
   "name": "env-s4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "a263f42c39b2fd75b37cb89946a27f6140cd004b337ff228565a862a637fff96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
